{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Abgegeben von (Name, Vorname):</span> \n",
    "Goxhufi, Driton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ähnlichkeitsmaße bei Wortformen\n",
    "\n",
    "Ähnlichkeitsmaße bei Wortformen spielen eine wichtige Rolle bei vielen Verfahren der NLP, insbesondere bei der Rechtschreibkorrektur. \n",
    "\n",
    "## Longest Common Substring\n",
    "\n",
    "Eine simple aber etwas naive Methode nimmt die (gewichtete) Länge des längsten gemeinsamen Substrings als Indikator für die Ähnlichkeit zweier Wörter. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2222222222222222"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code from https://www.geeksforgeeks.org/sequencematcher-in-python-for-longest-common-substring/\n",
    "from difflib import SequenceMatcher \n",
    "  \n",
    "def longestSubstring(str1,str2): \n",
    "  \n",
    "     # initialize SequenceMatcher object with  \n",
    "     # input string \n",
    "     seqMatch = SequenceMatcher(None,str1,str2) \n",
    "  \n",
    "     # find match of longest sub-string \n",
    "     # output will be like Match(a=0, b=0, size=5) \n",
    "     match = seqMatch.find_longest_match(0, len(str1), 0, len(str2)) \n",
    "  \n",
    "     # print longest substring \n",
    "     if (match.size!=0): \n",
    "          return(str1[match.a: match.a + match.size]) \n",
    "     else: \n",
    "          return(\"\")\n",
    "    \n",
    "def lcs_distance(w1,w2) :\n",
    "    return len(longestSubstring(w1,w2)) / len(w1 + w2)\n",
    "    \n",
    "lcs_distance(\"execution\",\"intention\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Problem ist hier natürlich, dass die Unterschiede zwischen zwei Wörtern so verteilt sein können, dass dieses Ähnlichkeitsmaß bei diesen Wörtern trotz der offensichtlichen Ähnlichkeit verhältnismäßig gering ausfällt.\n",
    "\n",
    "Beispiel:\n",
    "- *Hunden*\n",
    "- *Hündin*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16666666666666666"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcs_distance(\"Hunden\",\"Hündin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Substring-Überlappung\n",
    "\n",
    "Ein anderes Ähnlichkeitsmaß betrachtet die Überschneidung der Mengen der Substrings anhand der **Jaccard-Distanz**:\n",
    "\n",
    "$$jaccard(A,B) = \\frac{|A \\cap B|}{|A \\cup B|}$$\n",
    "\n",
    "Hier wären $A$ und $B$ die Mengen der Substrings zweier Wortformen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hunden, Hündin: 0.1111111111111111\n",
      "execution, intention: 0.1506849315068493\n"
     ]
    }
   ],
   "source": [
    "w1 = \"Hunden\"\n",
    "w2 = \"Hündin\"\n",
    "\n",
    "w3 = \"execution\"\n",
    "w4 = \"intention\"\n",
    "\n",
    "def substrings (string) :\n",
    "    return set([string[i: j] for i in range(len(string)) \n",
    "                for j in range(i + 1, len(string) + 1) \n",
    "                #if len(string[i: j]) > 1 and len(string[i: j]) < 3 \n",
    "               ]) \n",
    "\n",
    "# Jaccard-Distanz\n",
    "def jd (setA,setB) :\n",
    "    return len(setA & setB) / len(setA | setB)\n",
    "\n",
    "print(\"{}, {}: {}\".format(w1,w2,jd(substrings(w1),substrings(w2))))\n",
    "print(\"{}, {}: {}\".format(w3,w4,jd(substrings(w3),substrings(w4))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit Distance (aka Levenshtein Distance)\n",
    "\n",
    "Die Ähnlichkeit von Wortformen wird standardmäßig mit der **Edit Distance** (Editierdistanz, [Levenshtein Distance](https://de.wikipedia.org/wiki/Levenshtein-Distanz) quantifiziert.\n",
    "\n",
    "Die Idee ist, dass es eine kleine Menge von Operationen gibt, nämlich {insert, delete, substitute, keep}, die auf Buchstaben angewandt werden können, um ein Wort A in ein Wort B umzuwandeln. \n",
    "\n",
    "Das folgende Beispiel (aus Jarafsky & Martin 2019) stellt eine solche Konversion von *intention* nach *execution* dar:\n",
    "\n",
    "| i            | n            | t            | e            | *            | n            | t            | i            | o            | n            |\n",
    "|--------------|--------------|--------------|--------------|--------------|--------------|--------------|--------------|--------------|--------------|\n",
    "| $\\downarrow$ | $\\downarrow$ | $\\downarrow$ | $\\downarrow$ | $\\downarrow$ | $\\downarrow$ | $\\downarrow$ | $\\downarrow$ | $\\downarrow$ | $\\downarrow$ |\n",
    "| *            | **e**        | **x**        | **e**        | **c**        | **u**        | **t**        | **i**        | **o**        | **n**        |\n",
    "| D            | S            | S            |              | I            | S            |              |              |              |              |\n",
    "\n",
    "Die Konversionsoperationen können dabei unterschiedlich gewichtet werden:\n",
    "- D(elete): 1\n",
    "- S(substitute) : 2\n",
    "- I(nsert): 1\n",
    "- (keep): 0\n",
    "\n",
    "Die Operation S ist deshalb \"teurer\" als D und I, weil hier quasi implizit D und I durchgeführt werden.\n",
    "\n",
    "Aus den angewandten Operationen und deren Gewicht ergibt sich dann, dass die Edit Distance zwischen *intention* und *execution* 8 beträgt.\n",
    "\n",
    "## Minimierung der Edit Distance \n",
    "\n",
    "(im Wesentlichen übernommen aus Jurafsky & Martin 2019)\n",
    "\n",
    "Nun gibt es für zwei Wortformen immer trivialerweise unendlich viele mögliche Werte als Edit Distance -- wir können ja beliebig Buchstaben hinzufügen und löschen. Aus diesen möglichen Distanzen interessiert uns aber eigentlich nur die *minimale* Distanz, die sogenannte Minimal Edit Distance oder $D_{Lev}$.\n",
    "\n",
    "Zur Berechnung von $D_{Lev}$ greift man auf die Methode der Dynamischen Programmierung zurück. D.h. man merkt sich Zwischenergebnisse und berechnet nicht für jeden Edit Path alles neu.\n",
    "\n",
    "Dafür wird eine Matrix/Tabelle erstellt, so dass die Buchstaben des einen Worts die Zeilen definieren und die Buchstaben des anderen Worts die Spalten. (Es spielt keine Rolle, welche Wortform in den Spalten und welche Wortform in den Zeilen steht.) \n",
    "\n",
    "Nehmen wir im Folgenden an, dass $w_1 =$ *execution* und $w_2 =$ *intention*. Das jeweils erste Zeichen ist das leere Zeichen \\# und die Tabelle wird in der Zelle $[1,1]$ mit $0$ initialisiert.  \n",
    "\n",
    "|       | \\# | e | x | e | c | u | t | i | o | n |\n",
    "|-------|----|---|---|---|---|---|---|---|---|---|\n",
    "| \\#    |  $0$ |   |   |   |   |   |   |   |   |   |\n",
    "| **i** |    |   |   |   |   |   |   |   |   |   |\n",
    "| **n** |    |   |   |   |   |   |   |   |   |   |\n",
    "| **t** |    |   |   |   |   |   |   |   |   |   |\n",
    "| **e** |    |   |   |   |   |   |   |   |   |   |\n",
    "| **n** |    |   |   |   |   |   |   |   |   |   |\n",
    "| **t** |    |   |   |   |   |   |   |   |   |   |\n",
    "| **i** |    |   |   |   |   |   |   |   |   |   |\n",
    "| **o** |    |   |   |   |   |   |   |   |   |   |\n",
    "| **n** |    |   |   |   |   |   |   |   |   |   |\n",
    "\n",
    "Im Anschluss wird die Tabelle von $[1,1]$ bis $[|w_1|+1,|w_2|+1]$ anhand der rekursiven Funktion $D$ ausgefüllt:\n",
    "\n",
    "$$\\begin{array}{ll}\n",
    "D(x,y) = min ( & D(x-1,y)+1,\\\\ \n",
    "& D(x,y-1)+1,\\\\\n",
    "& D(x-1,y-1)+2,\\\\\n",
    "& D(x-1,y-1) ~\\mathit{iff}~ w_1[x]=x_2[y])\n",
    "\\end{array}$$\n",
    "\n",
    "Dabei soll gelten: \n",
    "\n",
    "$$D(0,y) = |w_2|+1 \\text{ und } D(x,0) = |w_1|+1$$ \n",
    "\n",
    "Wir erhalten schließlich die folgende vollständig ausgefüllte Tabelle:\n",
    "\n",
    "|       | \\#  | e   | x   | e    | c    | u    | t    | i    | o    | n    |\n",
    "|-------|-----|-----|-----|------|------|------|------|------|------|------|\n",
    "| \\#    | $0$ | $1$ | $2$ | $3$  | $4$  | $5$  | $6$  | $7$  | $8$  | $9$  |\n",
    "| **i** | $1$ | $2$ | $3$ | $4$  | $5$  | $6$  | $7$  | $6$  | $7$  | $8$  |\n",
    "| **n** | $2$ | $3$ | $4$ | $5$  | $6$  | $7$  | $8$  | $7$  | $8$  | $7$  |\n",
    "| **t** | $3$ | $4$ | $5$ | $6$  | $7$  | $8$  | $7$  | $8$  | $9$  | $8$  |\n",
    "| **e** | $4$ | $3$ | $4$ | $5$  | $6$  | $7$  | $8$  | $9$  | $10$ | $9$  |\n",
    "| **n** | $5$ | $4$ | $5$ | $6$  | $7$  | $8$  | $9$  | $10$ | $11$ | $10$ |\n",
    "| **t** | $6$ | $5$ | $6$ | $7$  | $8$  | $9$  | $8$  | $9$  | $10$ | $11$ |\n",
    "| **i** | $7$ | $6$ | $7$ | $8$  | $9$  | $10$ | $9$  | $8$  | $9$  | $10$ |\n",
    "| **o** | $8$ | $7$ | $8$ | $9$  | $10$ | $11$ | $10$ | $9$  | $8$  | $9$  |\n",
    "| **n** | $9$ | $8$ | $9$ | $10$ | $11$ | $12$ | $11$ | $10$ | $9$  | $8$  |\n",
    "\n",
    "$D_{Lev}(w_1,w_2)$ ist dann der Inhalt der Zelle $[|w_1|+1,|w_2|+1]$, also $8$.\n",
    "\n",
    "\n",
    "## <span style=\"color:red\">Aufgaben I</span>\n",
    "\n",
    "<span style=\"color:red\">A1:</span> Implementieren Sie $D_{Lev}$ in Python ohne NLTK mittels einer Funktion `d_lev(w1,w2)` und führen Sie den darunter stehenden Test aus!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im nachnihein ein iterativen ansatz versucht...\n",
    "def d_lev(str1, str2):\n",
    "    m = len(str1)\n",
    "    n = len(str2)\n",
    "    lensum = float(m + n)\n",
    "    d = []           \n",
    "    for i in range(m+1):\n",
    "        d.append([i])        \n",
    "    del d[0][0]    \n",
    "    for j in range(n+1):\n",
    "        d[0].append(j)       \n",
    "    for j in range(1,n+1):\n",
    "        for i in range(1,m+1):\n",
    "            if str1[i-1] == str2[j-1]:\n",
    "                d[i].insert(j,d[i-1][j-1])           \n",
    "            else:\n",
    "                minimum = min(d[i-1][j]+1, d[i][j-1]+1, d[i-1][j-1]+2)         \n",
    "                d[i].insert(j, minimum)\n",
    "    ldist = d[-1][-1]\n",
    "    return ldist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lösung A1\n",
    "# D(x,y)=min(D(x−1,y)+1,\n",
    "# D(x,y−1)+1,\n",
    "# D(x−1,y−1)+2,\n",
    "# D(x−1,y−1) iff w1[x]=x2[y]) \n",
    "\n",
    "memo = {}\n",
    "def d_lev(w1, w2):\n",
    "    if w1 == \"\":\n",
    "        return len(w2)\n",
    "    if w2 == \"\":\n",
    "        return len(w1)\n",
    "    cost = 0 if w1[-1] == w2[-1] else 1\n",
    "       \n",
    "    i1 = (w1[:-1], w2)             # D(x−1,y)+1\n",
    "    if not i1 in memo:\n",
    "        memo[i1] = d_lev(*i1)    \n",
    "    i2 = (w1, w2[:-1])             # D(x,y−1)+1,\n",
    "    if not i2 in memo:\n",
    "        memo[i2] = d_lev(*i2)    \n",
    "    i3 = (w1[:-1], w2[:-1])        # D(x−1,y−1)+2,\n",
    "    if not i3 in memo:\n",
    "        memo[i3] = d_lev(*i3)      # D(x−1,y−1) iff w1[x]=x2[y]\n",
    "    res = min([memo[i1]+1, \n",
    "               memo[i2]+1, \n",
    "               memo[i3]+cost])     # min(...)\n",
    "    \n",
    "    return res                     # D(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 8, 2]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tests für d_lev()\n",
    "\n",
    "[d_lev(i,j) for i,j in \n",
    " [(\"intention\",\"intention\"),\n",
    "  (\"execution\",\"intention\"),\n",
    "  (\"inetntion\",\"intention\")]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit Distance in NLTK\n",
    "\n",
    "NLTK stellt die entsprechende Funktion `edit_distance(s1,s2)` im Modul [`metrics`](https://www.nltk.org/api/nltk.metrics.html#module-nltk.metrics.distance) zur Verfügung.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 5, 2]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.metrics import edit_distance\n",
    "\n",
    "[edit_distance(i,j) for i,j in \n",
    " [(\"intention\",\"intention\"),\n",
    "  (\"execution\",\"intention\"),\n",
    "  (\"inetntion\",\"intention\")]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">Aufgaben II</span>\n",
    "\n",
    "<span style=\"color:red\">A2:</span> Ändern Sie den Aufruf von `edit_distance()` so, dass dieselben Werte wie bei `d_lev()` ausgegeben werden!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lösung A2\n",
    "# hmmm meine lösung gibt bereits die selben werte aus :).\n",
    "# Lösung A1\n",
    "# D(x,y)=min(D(x−1,y)+1,\n",
    "# D(x,y−1)+1,\n",
    "# D(x−1,y−1)+2,\n",
    "# D(x−1,y−1) iff w1[x]=x2[y]) \n",
    "\n",
    "memo = {}\n",
    "def d_lev(w1, w2):\n",
    "    if w1 == \"\":\n",
    "        return len(w2)\n",
    "    if w2 == \"\":\n",
    "        return len(w1)\n",
    "    cost = 0 if w1[-1] == w2[-1] else 1\n",
    "       \n",
    "    i1 = (w1[:-1], w2)             # D(x−1,y)+1\n",
    "    if not i1 in memo:\n",
    "        memo[i1] = d_lev(*i1)    \n",
    "    i2 = (w1, w2[:-1])             # D(x,y−1)+1,\n",
    "    if not i2 in memo:\n",
    "        memo[i2] = d_lev(*i2)    \n",
    "    i3 = (w1[:-1], w2[:-1])        # D(x−1,y−1)+2,\n",
    "    if not i3 in memo:\n",
    "        memo[i3] = d_lev(*i3)      # D(x−1,y−1) iff w1[x]=x2[y]\n",
    "    res = min([memo[i1]+1, \n",
    "               memo[i2]+1, \n",
    "               memo[i3]+cost])     # min(...)\n",
    "    \n",
    "    return res                     # D(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rechtschreibkorrektur mit Hilfe der Edit Distance\n",
    "\n",
    "Mit Hilfe der Edit Distance ist es recht einfach, ein Programm zu schreiben, das Vorschläge zur Rechtschreibkorrektur machen kann. Man braucht dafür im Grunde nur noch eine Liste mit Worten, die als Korrektur vorgeschlagen werden sollen. Im Prinzip funktionieren so auch aktuelle Korrekturhilfen wie [Aspell](http://aspell.net/man-html/Aspell-Suggestion-Strategy.html#Aspell-Suggestion-Strategy) oder Hunspell. Wir werden im Folgenden sehen, wie das für das Englische umgesetzt werden kann.\n",
    "\n",
    "Die Wortliste können wir einfach aus den Worten im Brown Corpus generieren. Außerdem nutzen wir eine Funktion `propose_word_corrections()`, die für einen Eingabestring diejenigen Worte aus einer Wortliste ausgibt, die maximal eine bestimmte Edit Distance (`edt`) zum Eingabestring haben. Als Funktion zur Ermittlung der Edit Distance dient uns diesmal `edit_distance()` aus NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "from nltk.metrics import edit_distance\n",
    "\n",
    "brownWords = set(brown.words())\n",
    "\n",
    "def propose_word_corrections (string,edt,lexicon) :\n",
    "    return [word for word in lexicon if edit_distance(word,string) <= edt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit `propose_word_corrections()` erhalten wir relativ zügig sinnvolle Vorschläge zur Rechtschreibkorrektur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['intentions',\n",
       " 'intention',\n",
       " 'infection',\n",
       " 'intuition',\n",
       " 'intentioned',\n",
       " 'invention',\n",
       " 'Attention',\n",
       " 'ingestion',\n",
       " 'intonation',\n",
       " 'inventions',\n",
       " 'intentional',\n",
       " 'inception',\n",
       " 'attention',\n",
       " 'contention',\n",
       " 'retention',\n",
       " 'Detention',\n",
       " 'detention',\n",
       " 'injection',\n",
       " 'insertion']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "propose_word_corrections(\"intention\",2,brownWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was nun noch stört, ist die Edit Distance Threshold `edt`. Wie könnte die automatisch gesetzt werden?\n",
    "\n",
    "## <span style=\"color:red\">Aufgaben III</span>\n",
    "\n",
    "<span style=\"color:red\">A3:</span> Implementieren Sie eine Funktion `lazy_propose_word_corrections(string,lexicon)`, die `edt` automatisch (und möglichst sinnvoll) anhand der Eingabe und der Ausgabe festlegt. Führen Sie damit den anschließenden Test aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lösung A3\n",
    "brownWords = set(brown.words())\n",
    "\n",
    "def lazy_propose_word_corrections(string,lexicon):\n",
    "    dist_list = []\n",
    "    for word in lexicon:\n",
    "        dist_list.append(edit_distance(word, string))\n",
    "    \n",
    "    edt = min(dist_list) # habe hier auch mit min(...)+1 gearbeitet, wäre auch sinnvoll um mehr vorschläge zu bekommen \n",
    "    print(\"the edt is: = \" + str(edt))\n",
    "    return [word for word in lexicon if edit_distance(word,string) <= edt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the edt is: = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['intention', 'invention']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test für lazy_propose_word_corrections()\n",
    "lazy_propose_word_corrections(\"inetntion\",brownWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probleme und Verbesserungsmöglichkeiten\n",
    "\n",
    "### Umfang der Wortliste\n",
    "\n",
    "Die Korrekturvorschläge werden auf Grundlage einer Wortliste gemacht. Diese Wortliste sollte im Idealfall alle korrekt geschriebenen Worte einer Sprache enthalten. Oben haben wir dafür das Brown Corpus verwendet und für das Englische war das bereits eine gute Approximation. \n",
    "\n",
    "Für eine Sprache wie das Deutsche gestaltet sich das aber schwieriger wegen der reichaltigeren Flexion und der Möglichkeit, Komposita ohne Leerzeichen zu bilden (*Eiersalatsoßengewürz*). Dadurch ist die Anzahl der Wortformen im Deutschen *wesentlich* höher als im Englischen. \n",
    "\n",
    "Heutzutage scheint das kein Problem mehr zu sein, denn man kann einfach ein riesigs Webcorpus nehmen (z.B. enthält [DECOW](https://corporafromtheweb.org/decow16/) mehr als 10 Milliarden Token), in dem Millionen von Wortformen enthalten sind. Das Problem ist aber dann, dass solche Ressourcen auch sehr untypische Wortformen enthalten, was die Korrekturhilfe einerseits zu tolerant macht und andererseits zu sehr vielen nutzlosen Vorschlägen führen kann. Und bestimmte Komposita werden auch dort nicht enthalten sein. \n",
    "\n",
    "Ein Lösungsansatz besteht darin, mehrstufig vorzugehen: Die Komposita werden zuerst getrennt und dann überprüft.\n",
    "\n",
    "Außerdem kann die Häufigkeit eines Wortes im Corpus verwendet werden, um die Liste der Korrekturvorschläge klein und möglichst sinnvoll zu halten. \n",
    "\n",
    "### Geschwindigkeit\n",
    "\n",
    "Der Umfang der Wortliste hat auch einen Einfluss auf die Geschwindigkeit der Rechtschreibkorrektur. Wenn so wie bei der  Funktion `propose_word_corrections()` die Edit Distance zu allen Worten der Wortlist einzeln berechnet wird, wird sich das auf die Geschwindigkeit gerade bei umfangreiche Wortlisten spürbar auswirken. Die Wortliste muss also irgendwie stärker strukturiert werden, um den Suchbereich sinnvoll einzugrenzen. \n",
    "\n",
    "Zudem könnte man die Berechnung der Edit Distance früher abbrechen, wenn ein Schwellenwert bekannt ist und aus dem Durchlauf der Tabelle klar wird, dass dieser nicht mehr erreicht oder unterboten werden kann.\n",
    "\n",
    "### Kontextabhängigkeit\n",
    "\n",
    "Wortformen wie *dass* und *das* sind nicht an alles Positionen im Satz gleich gut. Ein \"intelligenter\" Rechtschreibkorrektor würde erkennen, dass *das* an der Stelle einer Konjunktion (*dass*, *weil*, *nachdem*, ...) falsch geschrieben ist. Dafür brauchen wir Informationen zum POS-Tag oder Informationen zum Kontext in einem Satz. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Editieroperationen und deren Gewichte\n",
    "\n",
    "Um die Qualität der Rechtschreibkorrektur zu erhöhen, können weitere Editieroperationen hinzugefügt und deren Gewichte optimiert werden. \n",
    "\n",
    "Wir haben z.B. oben schon gesehen, dass Subsitution mal mit 1 und mal mit 2 gewichtet wird. Außerdem könnte man sich überlegen, die Gewichtung abhängig von der relativen Position auf der Tastatur festzulegen: Wenn wir eine Substitution von zwei Buchstaben wie *i* und *o* haben, dann sollte das geringer gewichtet werden als eine Substitution von *i* und *s*. Leider ist es gar nicht so trivial, die Gewichte relativ zueinander optimal festzulegen. Man wird hier wohl sehr viele Testdurchläufe brauchen (siehe unten) ...\n",
    "\n",
    "Was die Editieroperationen betrifft, stellt `edit_distance()` zusätzlich noch die **Transposition** zur Verfügung. Diese Operationen fasst im Grunde eine Deletion und eine Insertion zusammen und ist damit der Substitution sehr ähnlich:\n",
    "\n",
    "- *in**et**ntion* $\\Rightarrow$ *in**te**ntion*\n",
    "\n",
    "Bei `edit_distance()` kann die Transposition mit dem Argument `transpositions=True` aktiviert werden und wird dann mit 1 gewichtet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "without transpositions: 2\n",
      "with transpositions: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"without transpositions: \" + str(edit_distance(\"inetntion\",\"intention\")))\n",
    "print(\"with transpositions: \"    + str(edit_distance(\"inetntion\",\"intention\",transpositions=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es sind natürlich noch weitere Editieroperationen denkbar. Z.B. wäre es manchmal hilfreich, ein Leerzeichen einfügen zu können.\n",
    "\n",
    "- *allright* $\\Rightarrow$ *all right*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation durch Testdaten\n",
    "\n",
    "Wir haben bis hierhin gesehen, dass es eine Reihe von Parametern (Distanzmaß, Editieroperationen, Gewichte, Wortliste, ...) gibt, die man bei der Implementierung einer Rechtschreibkorrektur festlegen muss. Die Frage ist, wie man das so machen kann, dass die Zielgrößen optimiert werden, nämlich: \n",
    "- niedriger Ressourcenverbrauch: Zeit, Strom, Speicher\n",
    "- hohe [Präzision](https://en.wikipedia.org/wiki/Precision_and_recall): $P = \\frac{tp}{tp+fp}$\n",
    "- hoher [Recall](https://en.wikipedia.org/wiki/Precision_and_recall): $R = \\frac{tp}{tp+fn}$\n",
    "- hohes [F1-Maß](https://en.wikipedia.org/wiki/F1_score): $F = \\frac{2*P*R}{P+R}$\n",
    "\n",
    "Außerdem müssen wir die Zielgrößen anhand konkreter Daten, dem sogenannten **Testset**, überprüfen. Es reicht nicht zu sagen: \"Ich glaube aber, dass diese Parameter besser sind.\"\n",
    "\n",
    "Tatsächlich wirft jedoch der Bedarf eines Testsets eine weitere nichttriviale Frage auf: Wie können wir ein Testset so zusammenstellen, dass die Qualität der Rechtschreibkorrektur *realistischerweise* gemessen werden kann. Tatsächlich erfordert das ein nicht unerhebliches Wissen hinsichtlich der Morphophonologie, der Tippergonomie, der typischen Fehler und der Erwartungshaltung der Nutzer ...\n",
    "\n",
    "Wir werden im Folgenden die Qualität unserer Rechtschreibkorrektoren anhand eines Testsets überprüfen. Als Testset verwenden wir das Testset von Aspell . \n",
    "\n",
    "## <span style=\"color:red\">Aufgaben IV</span>\n",
    "\n",
    "<span style=\"color:red\">A4:</span> Laden Sie das Testset von Aspell (http://aspell.net/test/cur/batch0.tab) herunter und verändern Sie die folgende Funktion `TEST_propose_word_corrections()` so, dass für eine Eingabe `s1` eine möglichst gute Korrekturliste hinsichtlich des F1-Maßes ausgegeben wird. Testen Sie anschließend die generierten Korrekturlisten mit dem darunter stehenden Skript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TBD - not finished yet...\n",
    "def TEST_propose_word_corrections(s1) :\n",
    "    out = []\n",
    "    #precision = tp /(tp+fp)\n",
    "    #recall = tp/(tp +fn)\n",
    "    #f1 = (2*precision*recall)/(precision + recall)\n",
    "    \n",
    "    # Lösung A4\n",
    "    dist_list = []\n",
    "    for word in lexicon:\n",
    "        dist_list.append(edit_distance(word, string))\n",
    "    \n",
    "    edt = min(dist_list) # habe hier auch mit min(...)+1 gearbeitet, wäre auch sinnvoll um mehr vorschläge zu bekommen \n",
    "    print(\"the edt is: = \" + str(edt))\n",
    "    \n",
    "    out = [word for word in lexicon if edit_distance(word,string) <= edt]\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'batch0.tab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-63b0d75453f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'import csv\\n\\nsumTrueCorrections = 0\\nsumFalseCorrections = 0\\nsumProposedCorrections = 0\\n\\nwith open(\\'batch0.tab\\') as tsvfile:\\n  reader = csv.reader(tsvfile, delimiter=\\'\\\\t\\')\\n  for row in reader:\\n        proposedCorrections = TEST_propose_word_corrections(row[0])\\n        sumProposedCorrections += len(proposedCorrections)\\n        if row[1] in proposedCorrections :\\n            sumTrueCorrections += 1\\n            print(\"TRUE:  \" + row[0] + \" :: \" + row[1] + \"\\\\t\" + str(len(proposedCorrections)))\\n        else :\\n            sumFalseCorrections += 1\\n            print(\"FALSE: \" + row[0] + \" :: \" + row[1] + \"\\\\t\" + str(len(proposedCorrections)))\\n\\nrecallCorrections = sumTrueCorrections / (sumTrueCorrections + sumFalseCorrections)\\nprecisionCorrections = (sumTrueCorrections + sumFalseCorrections)/sumProposedCorrections\\n\\nprint(\"Recall:    \" + str(recallCorrections))   \\nprint(\"Precision: \" + str(precisionCorrections))\\nprint(\"F1 score:  \" + str(2 * precisionCorrections * recallCorrections / (precisionCorrections + recallCorrections)))\\n    '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mc:\\program files\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2101\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2103\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2104\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32mc:\\program files\\python36\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\program files\\python36\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1174\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'batch0.tab'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import csv\n",
    "\n",
    "sumTrueCorrections = 0\n",
    "sumFalseCorrections = 0\n",
    "sumProposedCorrections = 0\n",
    "\n",
    "with open('batch0.tab') as tsvfile:\n",
    "  reader = csv.reader(tsvfile, delimiter='\\t')\n",
    "  for row in reader:\n",
    "        proposedCorrections = TEST_propose_word_corrections(row[0])\n",
    "        sumProposedCorrections += len(proposedCorrections)\n",
    "        if row[1] in proposedCorrections :\n",
    "            sumTrueCorrections += 1\n",
    "            print(\"TRUE:  \" + row[0] + \" :: \" + row[1] + \"\\t\" + str(len(proposedCorrections)))\n",
    "        else :\n",
    "            sumFalseCorrections += 1\n",
    "            print(\"FALSE: \" + row[0] + \" :: \" + row[1] + \"\\t\" + str(len(proposedCorrections)))\n",
    "\n",
    "recallCorrections = sumTrueCorrections / (sumTrueCorrections + sumFalseCorrections)\n",
    "precisionCorrections = (sumTrueCorrections + sumFalseCorrections)/sumProposedCorrections\n",
    "\n",
    "print(\"Recall:    \" + str(recallCorrections))   \n",
    "print(\"Precision: \" + str(precisionCorrections))\n",
    "print(\"F1 score:  \" + str(2 * precisionCorrections * recallCorrections / (precisionCorrections + recallCorrections)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Man kann die Ergebnisse dann mit denen von Aspell vergleichen: http://aspell.net/test/cur/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
