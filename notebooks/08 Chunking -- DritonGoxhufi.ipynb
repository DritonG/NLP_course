{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Abgegeben von (Name, Vorname):</span> \n",
    "Goxhufi, Driton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Immer griffbereit:\n",
    "- Website: https://www.nltk.org/\n",
    "- Buch: https://www.nltk.org/book/\n",
    "- Module: https://www.nltk.org/py-modindex.html\n",
    "- Beispiele: http://www.nltk.org/howto/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sätze: Chunking\n",
    "\n",
    "Zu wissen, was in einem Text die Sätze und Worte (qua Tokenisierung) und die POS-Tags der Worte (qua POS-Tagging) sind, reicht natürlich oft nicht aus, um etwas sinnvolles über den Inhalt des Textes sagen können. Wenn wir nur das Nomen *York* sehen, wissen wir noch nicht, ob [York](https://de.wikipedia.org/wiki/York) oder [New York](https://de.wikipedia.org/wiki/New_York_City) gemeint ist. Das Chunking ist eine Methode, um größere, wortübergreifende Einheiten in einem Satz zu identifizieren. \n",
    "\n",
    "## Was ist Chunking?\n",
    "\n",
    "Unter Chunking versteht man die **überschneidungsfreie Gruppierung von benachbarten Wordtoken aufgrund ihres POS-Tags**. Zum Beispiel können Artikel, Adjektive und Nomen zu einem Chunk mit dem Label `NP` (für Nominalphrase) zusammengefasst werden:\n",
    "\n",
    "<img src=\"https://www.nltk.org/images/chunk-segmentation.png\" alt=\"Drawing\" style=\"width: 500px\"/>\n",
    "\n",
    "Die Chunks werden üblicherweise mittels einer **Klammernotation** aufgeschrieben: \n",
    "\n",
    "    (LABEL wordform1/TAG1 wordform2/TAG2 ...)\n",
    "    \n",
    "Also können wir obiges Beispiel folgendermaßen aufschreiben (und fügen dabei den Satz-Chunk hinzu):\n",
    "\n",
    "    (S\n",
    "      (NP We/PRP)\n",
    "      saw/VBD\n",
    "      (NP the/DT yellow/JJ dog/NN))\n",
    "\n",
    "Chunks können nicht nur Wortoken sondern auch Chunks enthalten. Dabei ist aber zu beachten, dass Chunks hinsichtlich des Labels **nicht rekursiv** sind! Das bedeutet beipielsweise, dass ein NP-Chunk kein anderes NP-Chunk enthalten darf.\n",
    "\n",
    "Also nicht so:\n",
    "\n",
    "    (S\n",
    "      (NP We/PRP)\n",
    "      saw/VBD\n",
    "      (NP the/DT yellow/JJ dog/NN \n",
    "        (PP of/IN                       # PP = Präpositionalphrase\n",
    "          (NP the/DT neighbor/NN))))    # Das geht nicht!\n",
    "          \n",
    "Sondern so: \n",
    "\n",
    "    (S\n",
    "      (NP We/PRP)\n",
    "      saw/VBD\n",
    "      (NP the/DT yellow/JJ dog/NN) \n",
    "      (PP of/IN \n",
    "        (NP the/DT neighbor/NN)))\n",
    "\n",
    "Oder noch flacher:\n",
    "\n",
    "    (S\n",
    "      (NP We/PRP)\n",
    "      saw/VBD\n",
    "      (NP the/DT yellow/JJ dog/NN) \n",
    "      (PP of/IN)\n",
    "      (NP the/DT neighbor/NN))\n",
    "      \n",
    "Man nennt das Chunking deshalb auch **Shallow Parsing**, weil die resultierenden Bäume flacher sind als beim \"tiefen\" Parsen (zu dem wir in der nächsten Sitzung kommen werden). \n",
    "\n",
    "Man kann übrigens mittels der NLTK-Klasse `Tree` solche Klammerausdrücke leicht einlesen, verändern und wieder ausgeben: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP We/PRP)\n",
      "  saw/VBD\n",
      "  (NP the/DT yellow/JJ dog/NN (PP of/IN (NP the/DT neighbor/NN))))\n"
     ]
    }
   ],
   "source": [
    "from nltk.tree import Tree\n",
    "\n",
    "chunked_sent = \"(S (NP We/PRP) saw/VBD (NP the/DT yellow/JJ dog/NN (PP of/IN (NP the/DT neighbor/NN))))\"\n",
    "\n",
    "print(Tree.fromstring(chunked_sent))   # Pretty-Print der Klammernotation\n",
    "Tree.fromstring(chunked_sent).draw()  # öffnet ein eigenes Fenter mit Baumdarstellung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Was ist ein Chunk? Und was nicht?\n",
    "\n",
    "Chunks sind Einheiten, die sich irgendwie \"sinnvoll\" von ihrer Umgebung abgrenzen lassen. Tatsächlich wird nie wirklich definitiert, was \"sinnvoll\" bedeutet. Man orientiert sich hier stattdessen an der Konstituenten- oder Phrasenstruktur und flacht diese nach bestimmten Regeln ab.\n",
    "\n",
    "**Beispiel:** Eine Konstituentestruktur ist oft rekursiv und sieht z.B. so aus:\n",
    "\n",
    "    (S\n",
    "      (NP We/PRP)\n",
    "      saw/VBD\n",
    "      (NP the/DT yellow/JJ dog/NN \n",
    "        (PP of/IN                       \n",
    "          (NP the/DT neighbor/NN))))\n",
    "\n",
    "Die Konstituentstruktur wird anhand sogenannter **Konstituententests** (auf die wir hier (noch) nicht eingehen wollen) gebildet. Solche Tests gibt es aber für Chunks meines Wissens nicht.\n",
    "\n",
    "Stattdessen werden Chunks aus solchen Konstituenstrukturen durch Abflachung gewonnen, indem z.B. die NP und die Präpositionalphrase aus der komplexen NP herausgenommen und \"angehoben\" werden:\n",
    "\n",
    "    (S\n",
    "      (NP We/PRP)\n",
    "      saw/VBD\n",
    "      (NP the/DT yellow/JJ dog/NN) \n",
    "      (PP of/IN)\n",
    "      (NP the/DT neighbor/NN))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methoden für das automatische Chunking\n",
    "\n",
    "Ein Satz mit $n$ Worten enthält maximal $n+1$ Chunks, aber es gibt $2^{(n-1)}$ mögliche Chunking-Analysen. D.h. ein durchschnittlicher Satz ($n =20$) kann auf 524288 Arten gechunkt werden.  Es stellt sich also die Frage, wie man aus dieser Masse an möglichen Chunking-Analysen die richtige auswählt. \n",
    "\n",
    "### Vorbereitung der Trainings- und Testdaten\n",
    "\n",
    "Für die Evaluierung der Methoden benötigen wir, ähnlich wie beim Tagging, disjunkte Trainings- und Testdaten mit Goldchunks. NLTK stellt hierfür mit `conll2000` das Chunk-Corpus des [CoNLL-2000-Shared-Task](https://www.aclweb.org/anthology/W00-0726/) bereit. Es enthält 10.948 Sätze und 259.104 Worttoken, was sicherlich ausreichend ist. <span style=\"color:red\">(Frage am Rande: Warum ist das wohl so?)</span> <span style=\"color:green\">Antwort: weniger POS-Tags, also Chung-Tags (weniger klassen)</span>\n",
    "\n",
    "Für die Abfrage von `conll2000` stehen die üblichen Methoden zu Verfügung (`words()`, `sents()`, `tagged_words()`, ...). Außerdem kann man hier aber mit `chunked_sents(chunk_types=None)` die enthaltenen Chunks ausgeben, wobei mit der Option `chunk_types` die Chunks anhand des Labels eingeschränkt werden können: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tree('S', [('Confidence', 'NN'), ('in', 'IN'), ('the', 'DT'), ('pound', 'NN'), Tree('VP', [('is', 'VBZ'), ('widely', 'RB'), ('expected', 'VBN'), ('to', 'TO'), ('take', 'VB')]), ('another', 'DT'), ('sharp', 'JJ'), ('dive', 'NN'), ('if', 'IN'), ('trade', 'NN'), ('figures', 'NNS'), ('for', 'IN'), ('September', 'NNP'), (',', ','), ('due', 'JJ'), ('for', 'IN'), ('release', 'NN'), ('tomorrow', 'NN'), (',', ','), Tree('VP', [('fail', 'VB'), ('to', 'TO'), ('show', 'VB')]), ('a', 'DT'), ('substantial', 'JJ'), ('improvement', 'NN'), ('from', 'IN'), ('July', 'NNP'), ('and', 'CC'), ('August', 'NNP'), (\"'s\", 'POS'), ('near-record', 'JJ'), ('deficits', 'NNS'), ('.', '.')]), Tree('S', [('Chancellor', 'NNP'), ('of', 'IN'), ('the', 'DT'), ('Exchequer', 'NNP'), ('Nigel', 'NNP'), ('Lawson', 'NNP'), (\"'s\", 'POS'), ('restated', 'VBN'), ('commitment', 'NN'), ('to', 'TO'), ('a', 'DT'), ('firm', 'NN'), ('monetary', 'JJ'), ('policy', 'NN'), Tree('VP', [('has', 'VBZ'), ('helped', 'VBN'), ('to', 'TO'), ('prevent', 'VB')]), ('a', 'DT'), ('freefall', 'NN'), ('in', 'IN'), ('sterling', 'NN'), ('over', 'IN'), ('the', 'DT'), ('past', 'JJ'), ('week', 'NN'), ('.', '.')]), ...]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import conll2000\n",
    " \n",
    "print(conll2000.chunked_sents(chunk_types=\"VP\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese Ausgabe besteht aus verschachtelten `Tree`-Objekten, die jeweils einen Mutterknoten und die Töchterknoten umfassen.\n",
    "\n",
    "D.h. wenn wir einen Satz auswählen, wird mit `print()` die Baumstruktur des `Tree`-Objekts besser lesbar ausgegeben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP Confidence/NN)\n",
      "  in/IN\n",
      "  (NP the/DT pound/NN)\n",
      "  is/VBZ\n",
      "  widely/RB\n",
      "  expected/VBN\n",
      "  to/TO\n",
      "  take/VB\n",
      "  (NP another/DT sharp/JJ dive/NN)\n",
      "  if/IN\n",
      "  (NP trade/NN figures/NNS)\n",
      "  for/IN\n",
      "  (NP September/NNP)\n",
      "  ,/,\n",
      "  due/JJ\n",
      "  for/IN\n",
      "  (NP release/NN)\n",
      "  (NP tomorrow/NN)\n",
      "  ,/,\n",
      "  fail/VB\n",
      "  to/TO\n",
      "  show/VB\n",
      "  (NP a/DT substantial/JJ improvement/NN)\n",
      "  from/IN\n",
      "  (NP July/NNP and/CC August/NNP)\n",
      "  (NP 's/POS near-record/JJ deficits/NNS)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "print(conll2000.chunked_sents(chunk_types=\"NP\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Man beachte, dass hier das [POS-Tagset der Penn Treebank](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html) verwendet wird.  \n",
    "\n",
    "Wichtig ist auch, dass das \"rohe\" CoNLL-2000-Corpus im sogenannten **CoNLL-Format** kodiert ist, bei dem jedes Wort und seine Tags eine Zeile bilden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence NN B-NP\n",
      "in IN B-PP\n",
      "the DT B-NP\n",
      "pound NN I-NP\n",
      "is VBZ B-VP\n",
      "widely RB I-VP\n",
      "expected VBN I-VP\n",
      "to TO I-VP\n",
      "take VB I-VP\n",
      "another DT B-NP\n",
      "sharp JJ I-NP\n",
      "dive NN I-NP\n",
      "if IN B-SBAR\n",
      "trade NN B-NP\n",
      "figur\n"
     ]
    }
   ],
   "source": [
    "print(conll2000.raw()[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Umfang der Chunks wird hier nicht mit Klammern, sondern mit Hilfe der **IOB-Annotation** (\"Inside\", \"Outside\", \"Beginning\") angezeigt. `B-NP` bedeutet etwa, das ein NP-Chunk an diesem Wort beginnt. Das Ende des Chunks wird durch ein mit `O` oder `B` annotiertes Wort markiert. <span style=\"color:red\">(Frage am Rande: Ist die IOB-Notation genauso ausdrucksstark wie die Klammernotation?)</span> \n",
    "\n",
    "Im Beispiel von oben sieht so aus, wobei hier nur NP-Chunking durchgeführt wird:\n",
    "\n",
    "<img src=\"https://www.nltk.org/images/chunk-tagrep.png\" alt=\"Drawing\" style=\"width: 500px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Praktischerweise sind die ConLL-Daten bereits in Trainings- und Testdaten aufgeteilt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vehältnis Testdaten/Trainingsdaten:  0.2251566696508505\n"
     ]
    }
   ],
   "source": [
    "conlltrain = conll2000.chunked_sents('train.txt')\n",
    "conlltest = conll2000.chunked_sents('train.txt')\n",
    "\n",
    "print(\"Vehältnis Testdaten/Trainingsdaten: \",len(conll2000.chunked_sents('test.txt'))/len(conll2000.chunked_sents('train.txt')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MFC-Baseline\n",
    "\n",
    "Vergleichbar mit dem POS-Tagging können wir uns erst einmal klar machen, wie schwer die Aufgabe ist, und eine einfache MFC-Baseline (\"Most Frequent Chunk\") bestimmen. Dafür schauen wir am besten auf die IOB-Annotation im rohen CoNLL2000-Corpus, da hier die einzelnen Wordtoken annotiert sind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I-NP', 63307),\n",
       " ('B-NP', 55081),\n",
       " ('O', 27902),\n",
       " ('B-VP', 21467),\n",
       " ('B-PP', 21281),\n",
       " ('I-VP', 12003),\n",
       " ('B-ADVP', 4227),\n",
       " ('B-SBAR', 2207),\n",
       " ('B-ADJP', 2060),\n",
       " ('I-ADJP', 643),\n",
       " ('B-PRT', 556),\n",
       " ('I-ADVP', 443),\n",
       " ('I-PP', 291),\n",
       " ('I-CONJP', 73),\n",
       " ('I-SBAR', 70),\n",
       " ('B-CONJP', 56),\n",
       " ('B-INTJ', 31),\n",
       " ('B-LST', 10),\n",
       " ('I-INTJ', 9),\n",
       " ('I-UCP', 6)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "\n",
    "chunkdist = FreqDist([chunktag for word,postag,chunktag in conll2000.iob_words('train.txt')])\n",
    "mfc = chunkdist.most_common(1)[0][0]\n",
    "\n",
    "chunkdist.most_common(20)\n",
    "# mfc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das häufigste Chunk-Tag ist also `I-NP`. Im Trainingskorpus wird dieses Tag immerhin bei knapp 30% der Wordtoken verwendet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.900296136062003"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * chunkdist.most_common(1)[0][1] / len(conll2000.iob_words('train.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dies ist also auch unsere Accuracy-Baseline, d.h. ein sehr einfacher Chunker, der jedes Worttoken mit dem Tag `I-NP` versieht, erreicht eine Accuracy in dieser Höhe. Korrekterweise müssen wir diesen Wert anhand der Testdaten errechnen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.34383772716719"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * FreqDist([chunktag for word,postag,chunktag in conll2000.iob_words('test.txt')]).most_common(1)[0][1] / len(conll2000.iob_words('test.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natürlich ist es noch nicht einmal theoretisch brauchbar, jedes Tolken mit `I-NP` zu taggen, weil das zu einem nicht wohlgeformten IOB-Muster führt. Trotzdem wollen wir der Vollständigkeit halber als erstes so einen Default-Chunker implementierten.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default-Chunker\n",
    "\n",
    "Ein Default-Chunker weist jedem Word dasselbe Chunk-Tag zu. NLTK bietet hierfür keine fertige Implementierung an; allerdings kann man dafür den Default-POS-Tagger aus der letzten Sitzung verwenden. Man muss dafür einfach POS-Tags wie Wortformen und Chunk-Tags wie POS-Tags behandeln:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://www.nltk.org/book/ch07.html\n",
    "class DefaultChunker(nltk.ChunkParserI):\n",
    "    def __init__(self, default): \n",
    "        self.tagger = nltk.DefaultTagger(default)\n",
    "\n",
    "    def parse(self, sentence):\n",
    "        pos_tags = [pos for (word,pos) in sentence]\n",
    "        tagged_pos_tags = self.tagger.tag(pos_tags)\n",
    "        chunktags = [chunktag for (pos, chunktag) in tagged_pos_tags]\n",
    "        conlltags = [(word, pos, chunktag) for ((word,pos),chunktag)\n",
    "                     in zip(sentence, chunktags)]\n",
    "        return nltk.chunk.conlltags2tree(conlltags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Chunker-Klassen, die vom Interface `ChunkerParserI` abgeleitet werden, haben eine Methode `evaluate(goldtestdata)`, mit der die Evaluation anhand von Goldtestdaten durchgeführt werden kann:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  32.6%%\n",
      "    Precision:      0.4%%\n",
      "    Recall:         0.0%%\n",
      "    F-Measure:      0.1%%\n"
     ]
    }
   ],
   "source": [
    "default_chunker = DefaultChunker('I-NP')\n",
    "print(default_chunker.evaluate(conlltest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die \"IOB Accuracy\" liegt zwar in einem Bereich, den wir erwartet haben, stimmt aber nicht exakt mit der oben berechneten Accuracy überein. Auch die Werte für Precision, Recall und F-Measure wirken erst einmal seltsam, weil sie sich erheblich von der IOB Accuracy unterscheiden. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Aufgaben I: Evaluation</span>\n",
    "\n",
    "<span style=\"color:red\">A1:</span> Geben sie je einen kurzen Erklärungsversuch für den Wert der IOB Accuracy und für die Werte Precision, Recall und F-Measure. Wie kommen diese Werte zustande und wie kann man deren großen Unterschied erklären? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\">Lösung A1</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### IOB Accuracy:\n",
    "Die accuracy gibt lediglich den prozentsatz der richtig vorausgesagten Chunk-Tags aus, also\n",
    "\n",
    "$\\frac{richtig klassifiziert}{richtig klassifiziert + falsch klassifiziert}$\n",
    "\n",
    "Wobei \"richtig klassifiziert\" aus $True Positive(TP) + True Negative(TN)$ besteht und falsch klassifiziert sich aus $False Positive(FP) + False Negative(FN)$ zusammensetzt.\n",
    "\n",
    "Also:\n",
    "\n",
    "$\\frac{TP + TN}{TP + TN + FP + FN}$\n",
    "\n",
    "Der Zähler ist dann einfach der MFC -> TP = 63307 und da wir nur \"I-NP\" klassifizieren gibt es keine TN =0 und auch keine FN = 0. Der Nenner ist die gesamte Anzahl aller Voraussagen(wort-länge des gesamten corpus) = 211727. FP sind alle Wörter die \"I-NP\" klassifiziert wurden, aber nicht zu dieser gehören, FP = 211727 - 63307. \n",
    "\n",
    "$\\frac{63307 + 0}{63307 + 0 + (211727-63307) + 0}$\n",
    "\n",
    "\n",
    "Dadurch gelangt man an einen hohen %-wert, wenn man das $mfc$ als chunk-Tag nutzt. \n",
    "##### Precision:\n",
    "Die Precision hingegen berücksichtigt im Zähler nur die $TP$ und im Nenner werden lediglich die Anzahl der Positiv klassifizierten samples einbezogen.\n",
    "\n",
    "$\\frac{True Positive}{True Positive + False Positive}$\n",
    "\n",
    "Daraus ergibt sich:\n",
    "\n",
    "$\\frac{63307}{63307 + False Positive}$\n",
    "\n",
    "##### Recall:\n",
    "\n",
    "$\\frac{True Positive}{True Positive + False Negative}$\n",
    "\n",
    "$\\frac{63307}{63307 + 0} = 0$\n",
    "\n",
    "\n",
    "##### F1-Measure:\n",
    "\n",
    "Und der F1-Score ist ein Wert der aus den beiden obrigen Metriken verrechnet wird:\n",
    "\n",
    "$F1 = 2\\times \\frac{Precision \\times Recall}{Precision + Recall}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.017881425569204"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * (chunkdist.most_common(1)[0][1] / (chunkdist.most_common(1)[0][1] + len(conll2000.iob_words('train.txt'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63307"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunkdist.most_common(1)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211727"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(conll2000.iob_words('train.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regexp-Chunker\n",
    "\n",
    "Wie beim POS-Tagging gibt es für das Chunkging ein regelbasiertes Verfahren mittels regulärer Ausdrücke. Dieses Verfahren benötigt keine Lerndaten, denn es können die Chunking-Regeln auf Grundlage der POS-Tags direkt angegeben werden.\n",
    "\n",
    "Man unterscheidet vier Arten von Chunking-Regeln:\n",
    "1. **Chunk:** Fasse die POS-Tags zu einem Chunk zusammen.\n",
    "2. **Chink:** Fasse die POS-Tags **nicht** zu einem Chunk zusammen.\n",
    "3. **Split:** Teile das Chunk an einer bestimmten Stelle. \n",
    "4. **Merge:** Fasse zwei Chunks zusammen.\n",
    "\n",
    "Die Reihenfolge der Rege-Typen kann beliebig festegelegt werden. Man kann zum Beispiel erst einen großen Chunk erstellen, diesen dann splitten, dann bestimmte Chunks chinken, dann wieder bestimmte Chunks mergen usw. \n",
    "\n",
    "Eine Regel beschreibt eine **Kette von POS- oder Chunk-Tags** mit Hilfe von regulären Operatoren:\n",
    "\n",
    "\n",
    "| **REGEXP** | **Beschreibung**                                     |\n",
    "| :-------   | :-------------------                                 |\n",
    "| `<NN>`     | ein Worttoken mit dem POS-Tag `NN`                   |\n",
    "| `<NN>+`    | ein oder mehr als ein Wordtoken mit dem POS-Tag `NN` |\n",
    "| `<NN.?>`   | ein Worttoken mit dem POS-Tag `NN` oder `NNS` oder `NNP`        |\n",
    "| `<NN\\|AT>`   | ein Worttoken mit dem POS-Tag `NN` oder `AT`         |\n",
    "| `<.*>`     | ein Wordtoken mit einem beliebigen POS-Tag           |\n",
    "| `<VP><NP>` | eine Verbalphrase gefolgt von einer Nominalphrase |\n",
    "\n",
    "Der Regel-Typ wird mit geschweiften Klammern angedeutet:\n",
    "\n",
    "| **REGEXP**           | **Beschreibung** |\n",
    "| :------------------- | :-------         |\n",
    "| `{REGEXP}`           | Chunk            |\n",
    "| `}REGEXP{`           | Chink            |\n",
    "| `REGEXP}{REGEXP}`    | Split            |\n",
    "| `REGEXP{}REGEXP`     | Merge            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier ein kleines Beispiel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP Rapunzel/NNP)\n",
      "  (VP let/VBD down/RP)\n",
      "  (NP her/PP$ long/JJ golden/JJ hair/NN))\n"
     ]
    }
   ],
   "source": [
    "grammar = r\"\"\"\n",
    "  NP:\n",
    "    {<.*>+}          # Chunk everything\n",
    "    }<VBD|IN|RP>+{   # Chink sequences of VBD, IN, RP\n",
    "  VP: \n",
    "    {<VBD><.*>+}     # Chunk VBD and everything following it\n",
    "    }<NP>{           # Chink NP chunks \n",
    "  \"\"\"\n",
    "regexp_chunker = nltk.RegexpParser(grammar)\n",
    "\n",
    "sentence = [(\"Rapunzel\", \"NNP\"), (\"let\", \"VBD\"), (\"down\", \"RP\"), \n",
    "                 (\"her\", \"PP$\"), (\"long\", \"JJ\"), (\"golden\", \"JJ\"), (\"hair\", \"NN\")]\n",
    "print(regexp_chunker.parse(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  47.2%%\n",
      "    Precision:     26.5%%\n",
      "    Recall:        13.7%%\n",
      "    F-Measure:     18.1%%\n"
     ]
    }
   ],
   "source": [
    "print(regexp_chunker.evaluate(conlltest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Aufgaben II: Regexp-Chunker </span>\n",
    "\n",
    "<span style=\"color:red\">A2:</span> Überlegen Sie sich sinnvolle Chunking-Regeln und implementieren Sie diese wie oben als reguläre Ausdrücke! Führen Sie eine Evaluation mit `evaluate()` durch und versuchen Sie einen möglichst hohen F1-Wert zu erzielen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP Rapunzel/NNP)\n",
      "  let/VBD\n",
      "  down/RP\n",
      "  her/PP$\n",
      "  (NP long/JJ golden/JJ hair/NN))\n"
     ]
    }
   ],
   "source": [
    "# Lösung A2\n",
    "\n",
    "mygrammar = r\"\"\"\n",
    "  NP: {<DT|JJ|NN.*>+}          # Chunk sequences of DT, JJ, NN\n",
    "  PP: {<IN><NP>}               # Chunk prepositions followed by NP\n",
    "  VP: {<VB.*><NP|PP|CLAUSE>+$} # Chunk verbs and their arguments\n",
    "  CLAUSE: {<NP><VP>}\n",
    "  \"\"\"\n",
    "my_regexp_chunker = nltk.RegexpParser(mygrammar)\n",
    "print(my_regexp_chunker.parse(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  51.2%%\n",
      "    Precision:     37.6%%\n",
      "    Recall:        19.6%%\n",
      "    F-Measure:     25.8%%\n"
     ]
    }
   ],
   "source": [
    "print(my_regexp_chunker.evaluate(conlltest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eine weitere Lösung wäre:\n",
    "mygrammar = r\"\"\"\n",
    "  NP: {<[CDJNP].*>+}\n",
    "  \"\"\"\n",
    "my_regexp_chunker = nltk.RegexpParser(mygrammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  61.9%%\n",
      "    Precision:     69.7%%\n",
      "    Recall:        38.0%%\n",
      "    F-Measure:     49.2%%\n"
     ]
    }
   ],
   "source": [
    "print(my_regexp_chunker.evaluate(conlltest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-Gram-Chunker\n",
    "\n",
    "Genauso wie beim POS-Tagging kann man auch beim Chunking die Tags der $n-1$ vorangegangenen Worttoken nutzen und dementsprechend Unigram-, Bigram- und Trigram-Chunker entwickeln. Tatsächlich kam dafür wie beim Default-Chunker oben die POS-Tagger wiederverwenden, indem man dafür einfach POS-Tags wie Wortformen und Chunk-Tags wie POS-Tags behandelt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from https://www.nltk.org/book/ch07.html\n",
    "class UnigramChunker(nltk.ChunkParserI):\n",
    "    def __init__(self, train_sents): \n",
    "        train_data = [[(t,c) for w,t,c in nltk.chunk.tree2conlltags(sent)]\n",
    "                      for sent in train_sents]\n",
    "        self.tagger = nltk.UnigramTagger(train_data)\n",
    "\n",
    "    def parse(self, sentence):\n",
    "        pos_tags = [pos for (word,pos) in sentence]\n",
    "        tagged_pos_tags = self.tagger.tag(pos_tags)\n",
    "        chunktags = [chunktag for (pos, chunktag) in tagged_pos_tags]\n",
    "        conlltags = [(word, pos, chunktag) for ((word,pos),chunktag)\n",
    "                     in zip(sentence, chunktags)]\n",
    "        return nltk.chunk.conlltags2tree(conlltags)\n",
    "    \n",
    "class BigramChunker(nltk.ChunkParserI):\n",
    "    def __init__(self, train_sents): \n",
    "        train_data = [[(t,c) for w,t,c in nltk.chunk.tree2conlltags(sent)]\n",
    "                      for sent in train_sents]\n",
    "        self.tagger = nltk.BigramTagger(train_data)\n",
    "\n",
    "    def parse(self, sentence):\n",
    "        pos_tags = [pos for (word,pos) in sentence]\n",
    "        tagged_pos_tags = self.tagger.tag(pos_tags)\n",
    "        chunktags = [chunktag for (pos, chunktag) in tagged_pos_tags]\n",
    "        conlltags = [(word, pos, chunktag) for ((word,pos),chunktag)\n",
    "                     in zip(sentence, chunktags)]\n",
    "        return nltk.chunk.conlltags2tree(conlltags)\n",
    "\n",
    "class TrigramChunker(nltk.ChunkParserI):\n",
    "    def __init__(self, train_sents): \n",
    "        train_data = [[(t,c) for w,t,c in nltk.chunk.tree2conlltags(sent)]\n",
    "                      for sent in train_sents]\n",
    "        self.tagger = nltk.TrigramTagger(train_data)\n",
    "\n",
    "    def parse(self, sentence):\n",
    "        pos_tags = [pos for (word,pos) in sentence]\n",
    "        tagged_pos_tags = self.tagger.tag(pos_tags)\n",
    "        chunktags = [chunktag for (pos, chunktag) in tagged_pos_tags]\n",
    "        conlltags = [(word, pos, chunktag) for ((word,pos),chunktag)\n",
    "                     in zip(sentence, chunktags)]\n",
    "        return nltk.chunk.conlltags2tree(conlltags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der Evaluation fallen zwei Dinge auf: \n",
    "1. Es wird kein Backoff benötigt, um eine einigermaßen akzeptable Performanz zu erzielen. <span style=\"color:red\">(Wieso?)</span>\n",
    "2. Trotzdem fällt die Performanz beim Trigram-Chunker im Vergleich zum Bigram-Chunker wieder etwas ab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  86.0%%\n",
      "    Precision:     73.7%%\n",
      "    Recall:        85.9%%\n",
      "    F-Measure:     79.3%%\n"
     ]
    }
   ],
   "source": [
    "unigram_chunker = UnigramChunker(conlltrain)\n",
    "print(unigram_chunker.evaluate(conlltest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  89.2%%\n",
      "    Precision:     80.8%%\n",
      "    Recall:        86.0%%\n",
      "    F-Measure:     83.3%%\n"
     ]
    }
   ],
   "source": [
    "bigram_chunker = BigramChunker(conlltrain)\n",
    "print(bigram_chunker.evaluate(conlltest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  88.1%%\n",
      "    Precision:     80.6%%\n",
      "    Recall:        84.7%%\n",
      "    F-Measure:     82.6%%\n"
     ]
    }
   ],
   "source": [
    "trigram_chunker = TrigramChunker(conlltrain)\n",
    "print(trigram_chunker.evaluate(conlltest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Aufgaben III: Backoff & Datenknappheit</span>\n",
    "\n",
    "<span style=\"color:red\">A3:</span> Implementieren Sie eine Backoff-Sequenz für die oben benutzen Chunker! (Denken Sie dabei an die Option `backoff`.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lösung A3\n",
    "class BackoffChunker(nltk.ChunkParserI):\n",
    "    def __init__(self, train_sents): \n",
    "        train_data = [[(t,c) for w,t,c in nltk.chunk.tree2conlltags(sent)]\n",
    "                      for sent in train_sents]\n",
    "        self.tagger = nltk.BigramTagger(train_data, backoff=nltk.UnigramTagger(train_data))\n",
    "\n",
    "    def parse(self, sentence):\n",
    "        pos_tags = [pos for (word,pos) in sentence]\n",
    "        tagged_pos_tags = self.tagger.tag(pos_tags)\n",
    "        chunktags = [chunktag for (pos, chunktag) in tagged_pos_tags]\n",
    "        conlltags = [(word, pos, chunktag) for ((word,pos),chunktag)\n",
    "                     in zip(sentence, chunktags)]\n",
    "        return nltk.chunk.conlltags2tree(conlltags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  89.3%%\n",
      "    Precision:     80.8%%\n",
      "    Recall:        86.1%%\n",
      "    F-Measure:     83.4%%\n"
     ]
    }
   ],
   "source": [
    "backoff_chunker = BackoffChunker(conlltrain)\n",
    "print(backoff_chunker.evaluate(conlltest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">A4:</span> Zeigen Sie, dass die Performanzeinbuße des Trigram-Chunkers gegenüber dem Bigram-Chunker wahrscheinlich durch Datenknappheit zustande kommt! (Tip: Welcher Chunk-Tag kommt denn am häufigsten vor?) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I-NP\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('I-NP', 14376),\n",
       " ('B-NP', 12422),\n",
       " ('O', 6180),\n",
       " ('B-PP', 4811),\n",
       " ('B-VP', 4658),\n",
       " ('I-VP', 2646),\n",
       " ('B-ADVP', 866),\n",
       " ('B-SBAR', 535),\n",
       " ('B-ADJP', 438),\n",
       " ('I-ADJP', 167),\n",
       " ('B-PRT', 106),\n",
       " ('I-ADVP', 89),\n",
       " ('I-PP', 48),\n",
       " ('I-CONJP', 13),\n",
       " ('B-CONJP', 9),\n",
       " ('B-LST', 5),\n",
       " ('I-SBAR', 4),\n",
       " ('B-INTJ', 2),\n",
       " ('I-LST', 2)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lösung A4 - leider keine Zeit mehr für diese Aufgabe... :(\n",
    "# Habe ich viele trigamms die zu selten vorkommen --> overfitten\n",
    "\n",
    "chunkdisttag = FreqDist([chunktag for word,postag,chunktag in conll2000.iob_words('test.txt')])\n",
    "mfc = chunkdisttag.most_common(1)[0][0]\n",
    "print(mfc)\n",
    "chunkdisttag.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ausblick: Klassifiziererbasierte Chunker\n",
    "\n",
    "Die bisher behandelten Verfahren nutzen ausschließlich POS-Tags für das Chunking. Dies führt zu gewissen Einschränkungen, da die nötigen Informationen nicht immer im POS-Tag verfügbar sind. \n",
    "\n",
    "Im NLTK-Buch wird folgendes Beispiel gegeben:\n",
    "\n",
    "    (3)\t\t\n",
    "        a.\t\tJoey/NN sold/VBD the/DT farmer/NN rice/NN ./.\n",
    "        b.\t\tNick/NN broke/VBD my/DT computer/NN monitor/NN ./.\n",
    "\n",
    "Der Chunker würde hier auf Grundlage der POS-Tags dieselbe Chunk-Struktur ausgeben. Dabei müssen die Sätze unterschiedlich analysiert werden, nämlich so:\n",
    "\n",
    "    (3')\t\t\n",
    "        a.\t\tJoey/NN sold/VBD (NP the/DT farmer/NN) (NP rice/NN) ./.\n",
    "        b.\t\tNick/NN broke/VBD (NP my/DT computer/NN monitor/NN) ./.\n",
    "\n",
    "Dem Chunker fehlt hier die Information, dass *sold* ditransitiv und *broke* transitiv ist. Außerdem ist *computer monitor* eine sogenannte **Kollokation**, d.h. eine geläufige komplexe NP, und *monitor* kann allein beine NP bilden. \n",
    "\n",
    "Um Wortformen zu berücksichtigen, aber dabei nicht in ein Sparse-Data-Problem zu geraten, bieten sich sogenannte klassifiziererbasierte Ansätze an. Im NLTK-Buch ist als Beispiel ein Naive-Bayes-Klassifizierer angegeben, bei dem die Features flexibel erstellt werden können. Hier der nur leicht veränderte Code und die Evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConsecutiveNPChunkTagger(nltk.TaggerI):\n",
    "    def __init__(self, train_sents):\n",
    "        train_set = []\n",
    "        for tagged_sent in train_sents:\n",
    "            untagged_sent = nltk.tag.untag(tagged_sent)\n",
    "            history = []\n",
    "            for i, (word, tag) in enumerate(tagged_sent):\n",
    "                featureset = npchunk_features(untagged_sent, i, history)\n",
    "                train_set.append( (featureset, tag) )\n",
    "                history.append(tag)\n",
    "        #self.classifier = nltk.MaxentClassifier.train( \n",
    "        #    train_set, algorithm='megam', trace=0)\n",
    "        self.classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "    def tag(self, sentence):\n",
    "        history = []\n",
    "        for i, word in enumerate(sentence):\n",
    "            featureset = npchunk_features(sentence, i, history)\n",
    "            tag = self.classifier.classify(featureset)\n",
    "            history.append(tag)\n",
    "        return zip(sentence, history)\n",
    "\n",
    "class ConsecutiveNPChunker(nltk.ChunkParserI):\n",
    "    def __init__(self, train_sents):\n",
    "        tagged_sents = [[((w,t),c) for (w,t,c) in\n",
    "                         nltk.chunk.tree2conlltags(sent)]\n",
    "                        for sent in train_sents]\n",
    "        self.tagger = ConsecutiveNPChunkTagger(tagged_sents)\n",
    "\n",
    "    def parse(self, sentence):\n",
    "        tagged_sents = self.tagger.tag(sentence)\n",
    "        conlltags = [(w,t,c) for ((w,t),c) in tagged_sents]\n",
    "        return nltk.chunk.conlltags2tree(conlltags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def npchunk_features(sentence, i, history):\n",
    "     word, pos = sentence[i]\n",
    "     if i == 0:\n",
    "        prevword, prevpos = \"<START>\", \"<START>\"\n",
    "     else:\n",
    "        prevword, prevpos = sentence[i-1]\n",
    "     if i == len(sentence)-1:\n",
    "         nextword, nextpos = \"<END>\", \"<END>\"\n",
    "     else:\n",
    "         nextword, nextpos = sentence[i+1]\n",
    "     return {\"pos\": pos,\n",
    "             \"word\": word,\n",
    "             \"prevpos\": prevpos,\n",
    "             \"nextpos\": nextpos, \n",
    "             \"prevpos+pos\": \"%s+%s\" % (prevpos, pos),   \n",
    "             \"pos+nextpos\": \"%s+%s\" % (pos, nextpos),\n",
    "             \"tags-since-dt\": tags_since_dt(sentence, i)}  \n",
    "\n",
    "def tags_since_dt(sentence, i):\n",
    "     tags = set()\n",
    "     for word, pos in sentence[:i]:\n",
    "         if pos == 'DT':\n",
    "             tags = set()\n",
    "         else:\n",
    "             tags.add(pos)\n",
    "     return '+'.join(sorted(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  93.0%%\n",
      "    Precision:     87.2%%\n",
      "    Recall:        91.9%%\n",
      "    F-Measure:     89.5%%\n"
     ]
    }
   ],
   "source": [
    "chunker = ConsecutiveNPChunker(conlltrain)\n",
    "print(chunker.evaluate(conlltest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir sehen, dass der Ansatz mit Bayes-Klassifizierer nochmals deutlich bessere Ergebnisse ermöglicht als die einfachen N-Gram-Chunker.\n",
    "\n",
    "Trotzdem liegt das noch gut 4 %-Punkte unter dem F-Measure der besten Chunker im CoNLL-Shared-Task vor bald 20 Jahre ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
