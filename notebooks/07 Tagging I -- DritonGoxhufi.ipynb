{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Abgegeben von (Name, Vorname):</span> \n",
    "Goxhufi, Driton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Immer griffbereit:\n",
    "- Website: https://www.nltk.org/\n",
    "- Buch: https://www.nltk.org/book/\n",
    "- Module: https://www.nltk.org/py-modindex.html\n",
    "- Beispiele: http://www.nltk.org/howto/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sätze: POS-Tagging  \n",
    "\n",
    "Das POS-Tagging ist wie die Tokenisierung ein wichtiger Vorverarbeitungsschritt bei der Analyse natürlicher Sprache.\n",
    "\n",
    "Unter POS-Tagging versteht man die **Wortartenklassifizierung** von Wordtoken anhand sogenannter **POS-Tags**. Zum Beispiel wird im ersten Satz des Brown Corpus ein Wordtoken *place* mit dem POS-Tag `NN` versehen, um anzuzeigen, dass es sich hierbei um ein Nomen handelt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('place', 'NN')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "\n",
    "brown.tagged_sents()[0][23]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das POS-Tagging hilft dabei, von der konkreten Wortform eines Tokens zu abstrahieren und (statistische) Zusammenhänge zwischen Worttoken leichter zu erkennen. Damit lässt sich z.B. leichter der grobe Bauplan eines Satzes angeben, ohne alle Möglichkeiten aufzählen zu müssen. Wir können dann Beschreibungen benutzen wie: \n",
    "\n",
    "- Ein Nomen steht oft direkt hinter einem Artikel.\n",
    "- Ein Artikel steht nie direkt hinter einem Artikel (zumindest im Englischen).\n",
    "- Ein Adjektiv steht oft zwischen einem Artikel und einem Nomen. \n",
    "- usw.\n",
    "\n",
    "POS-Tags könnnen auch bei Suchanfragen verwendet werden, etwa um [Konkordanzen](#Exkurs:-Konkordanzen) zu erstellen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exkurs: Konkordanzen\n",
    "\n",
    "Konkordanzen sind alignierte Trefferlisten ([Wikipedia](https://de.wikipedia.org/wiki/Konkordanz_\\(Textwissenschaft\\)#Konkordanzsoftware)), wobei die Suchanfragen nicht nur Wortformen, sondern auch POS-Tags enthalten können.\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/de/d/d4/Konkordanz_Nationalrat.png)\n",
    "\n",
    "Konkordanzen sind in der Linguistik sehr wichtig für die Datenrecherche, denn sie stellen gefundene Belege übersichtlich dar. NLTK enthält ebenfalls einen sogenannten **Concordancer**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.app.concordance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wortarten und Tagsets\n",
    "\n",
    "Ein POS-Tag zeigt die [**Wortart**](https://de.wikipedia.org/wiki/Wortart) (engl.: part of speech) eines Wortokens an. Die Wortart wird abhängig von der Morphologie (d.h. Wortform), der Syntax (d.h. der Umgebung des Worttokens im Satz) und der Semantik (d.h. Wortbedeutung) bestimmt und soll wichtige Eigenschaften dieser Aspekte zusammenfassen.\n",
    "\n",
    "**Beispiel:** Nomen (Substantiv, engl.: noun)\n",
    "- Morphologie: hat bestimmte Merkmale (z.B. Kasus, Numerus, Genus), ggf. erkennbar an bestimmten Derivationsaffixen (-*ness*) und Flexionsaffixen (-*es*)\n",
    "- Syntax: steht hinter einem Artikel oder Adjektiv und bildet mit diesen eine [Konstituente](https://de.wikipedia.org/wiki/Konstituente)\n",
    "- Semantik: bezeichnet (im prototypischen Fall) eine Sache\n",
    "\n",
    "Je nach Auswahl und Granularität der morphologischen, syntaktischen und semantischen Eigenschaften können unterschiedliche **Tagsets** definiert werden. Für das Englische gibt es zum Beispiel drei sehr weit verbreitete Tagsets:\n",
    "\n",
    "- [Tagset des Brown Corpus](https://en.wikipedia.org/wiki/Brown_Corpus#Part-of-speech_tags_used)\n",
    "- [Tagset der Penn Treebank (PTB)](https://www.sketchengine.eu/english-treetagger-pipeline-2/)\n",
    "- [Tagset des Brittish National Corpus (BNC)](http://www.natcorp.ox.ac.uk/docs/c5spec.html)\n",
    "\n",
    "Für das Deutsche hat sich das [Stuttgart-Tübingen Tagset (STTS)](https://homepage.ruhr-uni-bochum.de/Stephen.Berman/Korpuslinguistik/Tagsets-STTS.html) durchgesetzt.\n",
    "\n",
    "Der Umfang eines Tagsets hängt nicht zuletzt davon ab, wie reich die Morphologie einer Sprache ist. Die Tagsets für morphologisch reichere Sprachen sind oft (aber nicht immer) umfangreicher als Tagsets für morphologisch einfachere Sprachen wie das Englische. Z.B. gibt es ein [Tagset für das Tschechische](https://www.sketchengine.eu/tagset-reference-for-czech/), das 4288 POS-Tags enthält.    \n",
    "\n",
    "NLTK stellt bei den getaggted Corpora neben dem ursprünglichen Tagset auch ein sogenanntes **Universelles Tagset** zur Verfügung. Dieses enthält im Wesentlichen die Hauptwortarten, die auch im Schulunterricht behandelt werden (und aus der griechischen/lateinischen Grammatikschreibung stammen). \n",
    "\n",
    "Das Universelle Tagset wurde im Rahmen der [**Universal-Dependencies-Initiative**](https://universaldependencies.org/) definiert und soll die Tagsets sprachübergreifend vereinheitlichen (weitere Informationen gibt es [hier](https://universaldependencies.org/u/pos/) und [hier](http://petrovi.de/data/universal.pdf)).\n",
    "\n",
    "Das Universelle Tagset kann mittels der Option `tagset='universal'` aufgerufen werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('The', 'DET'), ('Fulton', 'NOUN'), ('County', 'NOUN'), ('Grand', 'ADJ'), ('Jury', 'NOUN'), ('said', 'VERB'), ('Friday', 'NOUN'), ('an', 'DET'), ('investigation', 'NOUN'), ('of', 'ADP'), (\"Atlanta's\", 'NOUN'), ('recent', 'ADJ'), ('primary', 'NOUN'), ('election', 'NOUN'), ('produced', 'VERB'), ('``', '.'), ('no', 'DET'), ('evidence', 'NOUN'), (\"''\", '.'), ('that', 'ADP'), ('any', 'DET'), ('irregularities', 'NOUN'), ('took', 'VERB'), ('place', 'NOUN'), ('.', '.')], [('The', 'DET'), ('jury', 'NOUN'), ('further', 'ADV'), ('said', 'VERB'), ('in', 'ADP'), ('term-end', 'NOUN'), ('presentments', 'NOUN'), ('that', 'ADP'), ('the', 'DET'), ('City', 'NOUN'), ('Executive', 'ADJ'), ('Committee', 'NOUN'), (',', '.'), ('which', 'DET'), ('had', 'VERB'), ('over-all', 'ADJ'), ('charge', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('election', 'NOUN'), (',', '.'), ('``', '.'), ('deserves', 'VERB'), ('the', 'DET'), ('praise', 'NOUN'), ('and', 'CONJ'), ('thanks', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('City', 'NOUN'), ('of', 'ADP'), ('Atlanta', 'NOUN'), (\"''\", '.'), ('for', 'ADP'), ('the', 'DET'), ('manner', 'NOUN'), ('in', 'ADP'), ('which', 'DET'), ('the', 'DET'), ('election', 'NOUN'), ('was', 'VERB'), ('conducted', 'VERB'), ('.', '.')], ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.tagged_sents(tagset='universal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK dokumentiert die genutzen POS-Tags aus dem Universellen Tagset folgendermaßen:\n",
    "\n",
    "| **Tag** | **Meaning**         | **English Examples**                     |\n",
    "| :------- | :------------------- | :---------------------------------------- |\n",
    "| `ADJ`   | adjective           | *new, good, high, special, big, local*   |\n",
    "| `ADP`   | adposition          | *on, of, at, with, by, into, under*      |\n",
    "| `ADV`   | adverb              | *really, already, still, early, now*     |\n",
    "| `CONJ`  | conjunction         | *and, or, but, if, while, although*      |\n",
    "| `DET`   | determiner, article | *the, a, some, most, every, no, which*   |\n",
    "| `NOUN`  | noun                | *year, home, costs, time, Africa*        |\n",
    "| `NUM`   | numeral             | *twenty-four, fourth, 1991, 14:24*       |\n",
    "| `PRT`   | particle            | *at, on, out, over, per, that, up, with*  |\n",
    "| `PRON`  | pronoun             | *he, their, her, its, my, I, us*         |\n",
    "| `VERB`  | verb                | *is, say, told, given, playing, would*   |\n",
    "| `.`     | punctuation marks   | *. , ; \\!*                               |\n",
    "| `X`     | other               | *ersatz, esprit, dunno, gr8, univeristy* |\n",
    "\n",
    "Das vollständige Universelle Tagset enthält außerdem `AUX` (\"auxiliary verb\"), `INTJ` (\"interjection\"), `PROPN` (\"proper noun\"), `SCONJ` (\"subordinating conjunction\") und `SYM` (\"symbol\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">Aufgaben I: Ambiguität beim POS-Tagging</span>\n",
    "\n",
    "Für das POS-Tagging reicht es oft nicht aus, nur die Wortform eines Tokens zu betrachten, denn oft kann dieselbe Wortformen unterschiedlichen POS-Tags zugeordnet werden. Wortformen sind also hinsichtlich der POS-Tags mehrdeutig/ambig.\n",
    "\n",
    "<span style=\"color:red\">A1:</span> Bestimmen Sie den Grad der POS-Tag-Ambiguität der Wortformen im Brown Corpus anhand der folgenden Kennzahlen:\n",
    "- durchschnittliche Anzahl der POS-Tags einer Wortform\n",
    "- die 10 Wortformen mit der höchsten Anzahl an POS-Tags\n",
    "- der %-Anteil der ambigen Wortformen bei den Wortformen\n",
    "- der %-Anteil der Worttoken mit ambiger Wortformen bei den Wortoken "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die durchschnittliche Anzahl der POS-Tags: 8379.5\n"
     ]
    }
   ],
   "source": [
    "# Lösung A1\n",
    "from collections import defaultdict\n",
    "\n",
    "counts = defaultdict(int)\n",
    "for (word, tag) in brown.tagged_words(categories='news', tagset='universal'):\n",
    "    counts[tag] += 1\n",
    "    \n",
    "n_pos_tags = len(counts.items())\n",
    "sum_numb_pos = sum(counts.values())\n",
    "avagerage_pos_tag_number = sum_numb_pos/12\n",
    "print(\"Die durchschnittliche Anzahl der POS-Tags:\", avagerage_pos_tag_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NOUN', 30654),\n",
       " ('VERB', 14399),\n",
       " ('ADP', 12355),\n",
       " ('.', 11928),\n",
       " ('DET', 11389),\n",
       " ('ADJ', 6706),\n",
       " ('ADV', 3349),\n",
       " ('CONJ', 2717),\n",
       " ('PRON', 2535),\n",
       " ('PRT', 2264)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 10 most frequent Tags\n",
    "from itertools import islice\n",
    "from operator import itemgetter\n",
    "\n",
    "def take(n, iterable):\n",
    "    \"return first n items\"\n",
    "    return list(islice(iterable, n))\n",
    "\n",
    "take(10, sorted(counts.items(), key=itemgetter(1), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100 * len({word for word in postdict if len(posdict[word]) > 1}) / len(postdict.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# durchschinittliche Anzahl der POS-Tags pro Worttoken\n",
    "mean([len(postdict[word]) for word in brown.words()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methoden des POS-Taggings\n",
    "\n",
    "Im Folgenden werden wir ein paar Methoden des POS-Taggings kennenlernen. Damit die jeweilige Leistungsfähigkeit gemessen und verglichen werden kann, müssen wir uns aber erst einmal mit dem Thema Evaluierung auseinander setzen.\n",
    "\n",
    "### Evaluierung mit Trainings- und Testdaten\n",
    "\n",
    "Für die Evaluierung der Tagger werden üblicherweise *Trainingsdaten* und *Testdaten* verwendet: Die Trainingsdaten enthalten bei überwachten Verfahren die POS-Tags, deren Zuweisung der Tagger anhand konkreter Einzeldaten lernen soll; die Testdaten stammen meist aus demselben (hand-)annotierten Corpus, aber hier fehlen die POS-Tags. **Wichtig ist, dass sich Trainings- und Testdaten nicht überschneiden!**\n",
    "\n",
    "Mit Hilfe des Brown Corpus lassen sich beide Datentypen leicht erstellen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testdaten: ['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.']\n",
      "\n",
      "Trainingsdaten: [('Daniel', 'NOUN'), ('personally', 'ADV'), ('led', 'VERB'), ('the', 'DET'), ('fight', 'NOUN'), ('for', 'ADP'), ('the', 'DET'), ('measure', 'NOUN'), (',', '.'), ('which', 'DET'), ('he', 'PRON'), ('had', 'VERB'), ('watered', 'VERB'), ('down', 'PRT'), ('considerably', 'ADV'), ('since', 'ADP'), ('its', 'DET'), ('rejection', 'NOUN'), ('by', 'ADP'), ('two', 'NUM'), ('previous', 'ADJ'), ('Legislatures', 'NOUN'), (',', '.'), ('in', 'ADP'), ('a', 'DET'), ('public', 'ADJ'), ('hearing', 'NOUN'), ('before', 'ADP'), ('the', 'DET'), ('House', 'NOUN'), ('Committee', 'NOUN'), ('on', 'ADP'), ('Revenue', 'NOUN'), ('and', 'CONJ'), ('Taxation', 'NOUN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tag import untag\n",
    "\n",
    "brown_train = brown.tagged_sents(categories='news', tagset='universal')[100:]\n",
    "brown_testgold = brown.tagged_sents(categories='news', tagset='universal')[:100]\n",
    "brown_test = [untag(sent) for sent in brown_testgold]\n",
    "\n",
    "print(\"Testdaten: {}\\n\".format(brown_test[0]))\n",
    "print(\"Trainingsdaten: {}\".format(brown_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NOUN'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#---------------------------------------------------------\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "posdict = FreqDist([tag for sent in brown_train for word,tag in sent]).most_common(1)[0][0]\n",
    "posdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ACHTUNG:** Die POS-Tagger werden immer auf einzelne tokenisierte Sätze angewandt. Die Satz- und Worttokenisierung muss also schon durchgeführt sein.\n",
    "\n",
    "Man kann nun zwei Dinge anhand der Testdaten und der Goldtestdaten messen:\n",
    "- Wie gut werden alle Worte klassifiziert?  $\\Rightarrow$ **Accurracy** (global precision)\n",
    "- Wie gut funktioniert die Klassifikation bei einzelnen POS-Tags? $\\Rightarrow$ **Precision**, **Recall**, **F1 Measure**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default-Tagger\n",
    "\n",
    "Der Default-Tagger weist immer dasselbe POS-Tag zu, egal welches Wort vorliegt. Im Unterschied zu einem Random-Tagger, der aus den POS-Tags zufällig eines auswählt, kann der Default-Tagger aus den Testdaten immerhin \"lernen\", welches POS-Tag am häufigsten ist.\n",
    "\n",
    "NLTK enthält bereits eine Klasse `DefaultTagger`, mit der in wenigen Zeilen ein Default-Tagger erstellt werden kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'POS'),\n",
       " ('Fulton', 'POS'),\n",
       " ('County', 'POS'),\n",
       " ('Grand', 'POS'),\n",
       " ('Jury', 'POS'),\n",
       " ('said', 'POS'),\n",
       " ('Friday', 'POS'),\n",
       " ('an', 'POS'),\n",
       " ('investigation', 'POS'),\n",
       " ('of', 'POS'),\n",
       " (\"Atlanta's\", 'POS'),\n",
       " ('recent', 'POS'),\n",
       " ('primary', 'POS'),\n",
       " ('election', 'POS'),\n",
       " ('produced', 'POS'),\n",
       " ('``', 'POS'),\n",
       " ('no', 'POS'),\n",
       " ('evidence', 'POS'),\n",
       " (\"''\", 'POS'),\n",
       " ('that', 'POS'),\n",
       " ('any', 'POS'),\n",
       " ('irregularities', 'POS'),\n",
       " ('took', 'POS'),\n",
       " ('place', 'POS'),\n",
       " ('.', 'POS')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import DefaultTagger\n",
    "dt = DefaultTagger('POS')\n",
    "dt.tag(brown_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun muss nur noch das häufigste POS-Tag in den Trainingsdaten ermittelt werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'NOUN'),\n",
       " ('Fulton', 'NOUN'),\n",
       " ('County', 'NOUN'),\n",
       " ('Grand', 'NOUN'),\n",
       " ('Jury', 'NOUN'),\n",
       " ('said', 'NOUN'),\n",
       " ('Friday', 'NOUN'),\n",
       " ('an', 'NOUN'),\n",
       " ('investigation', 'NOUN'),\n",
       " ('of', 'NOUN'),\n",
       " (\"Atlanta's\", 'NOUN'),\n",
       " ('recent', 'NOUN'),\n",
       " ('primary', 'NOUN'),\n",
       " ('election', 'NOUN'),\n",
       " ('produced', 'NOUN'),\n",
       " ('``', 'NOUN'),\n",
       " ('no', 'NOUN'),\n",
       " ('evidence', 'NOUN'),\n",
       " (\"''\", 'NOUN'),\n",
       " ('that', 'NOUN'),\n",
       " ('any', 'NOUN'),\n",
       " ('irregularities', 'NOUN'),\n",
       " ('took', 'NOUN'),\n",
       " ('place', 'NOUN'),\n",
       " ('.', 'NOUN')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "\n",
    "# Default-Tagger beim Lernen\n",
    "mfpos = FreqDist([tag for sent in brown_train for word,tag in sent]).most_common(1)[0][0]\n",
    "\n",
    "dt = DefaultTagger(mfpos)\n",
    "dt.tag(brown_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für die Evaluation steht bei Tagger-Objekten glücklicherweise die Methode `evaluate()` zur Verfügung. Bitte daran denken, dass jetzt die Goldtestdaten verwendet werden müssen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31790123456790126"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.evaluate(brown_testgold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine Accuracy von 31,8% ist wirklich sehr niedrig -- vor allem da wir wissen, dass nur ein POS-Tag verwendet wird. Der Informationsgewinn ist also gleich null."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regexp-Tagger\n",
    "\n",
    "Während der Default-Tagger die Wortform ignoriert, geht es beim Regexp-Tagger darum, allein aus der Wortform das POS-Tag zu erschließen. Trainingsdaten werden also nicht benötigt. \n",
    "\n",
    "NLTK enthält hierfür die Klasse `RegexpTagger`, an die wie `DefaultTagger` bedient werden kann (beide implementieren das Interface `TaggerI`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DET'),\n",
       " ('Fulton', 'NOUN'),\n",
       " ('County', 'NOUN'),\n",
       " ('Grand', 'NOUN'),\n",
       " ('Jury', 'NOUN'),\n",
       " ('said', 'NOUN'),\n",
       " ('Friday', 'NOUN'),\n",
       " ('an', 'DET'),\n",
       " ('investigation', 'NOUN'),\n",
       " ('of', 'NOUN'),\n",
       " (\"Atlanta's\", 'NOUN'),\n",
       " ('recent', 'NOUN'),\n",
       " ('primary', 'NOUN'),\n",
       " ('election', 'NOUN'),\n",
       " ('produced', 'VERB'),\n",
       " ('``', '.'),\n",
       " ('no', 'NOUN'),\n",
       " ('evidence', 'NOUN'),\n",
       " (\"''\", '.'),\n",
       " ('that', 'NOUN'),\n",
       " ('any', 'NOUN'),\n",
       " ('irregularities', 'VERB'),\n",
       " ('took', 'NOUN'),\n",
       " ('place', 'NOUN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import RegexpTagger\n",
    "rt = RegexpTagger([\n",
    "    (r'(The|the|A|a|An|an)$', 'DET'),      # articles\n",
    "    (r'.*able$', 'ADJ'),                   # adjectives\n",
    "    (r'.*ness$', 'NOUN'),                  # nouns formed from adjectives\n",
    "    (r'.*ly$', 'ADV'),                     # adverbs\n",
    "    (r'.*ing$', 'VERB'),                   # gerunds\n",
    "    (r'.*ed$', 'VERB'),                    # simple past\n",
    "    (r'.*es$', 'VERB'),                    # 3rd singular present\n",
    "    (r'.*ies$', 'NOUN'),\n",
    "    (r'.*ould$', 'VERB'),                  # modals\n",
    "    (r'.*\\'s$', 'NOUN'),                   # possessive nouns\n",
    "    (r'.*s$', 'NOUN'),                     # plural nouns\n",
    "    (r'^-?[0-9]+(\\.[0-9]+)?$', 'NUM'),     # cardinal numbers\n",
    "    (r'(\\.|\\,|\\(|\\)|\\;|\\`\\`|\\'\\')$', '.'), # punctuation\n",
    "    (r'.*', 'NOUN'),                       # nouns (default)\n",
    "    ])\n",
    "\n",
    "rt.tag(brown_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5868606701940036"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt.evaluate(brown_testgold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Accuracy ist nun deutlich erhöht, aber immer noch zu niedrig. Das grundsätzliche Problem hier ist, dass die regulären Ausdrücke nicht immer eindeutig einem POS-Tag zugeordnet werden können. Außerdem vergisst man leicht eine Regel, wodurch sich die Abdeckung verringert.\n",
    "\n",
    "### Lookup-Tagger\n",
    "\n",
    "Die Idee beim Lookup-Tagger ist, für jedes Wort das POS-Tag in einem \"Wörterbuch\" nachzuschlagen. Dieses Wörterbuch kann ad hoc aus den Trainingsdaten generiert werden, indem für jede Wortform das häufigste POS-Tag gespeichert wird.\n",
    "\n",
    "Da man hier nur einzelne Wortformen und Token betrachtet, spricht man auch von einem **Unigram-Tagger**. Wie schon beim Default-Tagger hält NLTK eine passende Klasse (`UnigramTagger`) bereit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DET'),\n",
       " ('Fulton', None),\n",
       " ('County', 'NOUN'),\n",
       " ('Grand', 'ADJ'),\n",
       " ('Jury', 'NOUN'),\n",
       " ('said', 'VERB'),\n",
       " ('Friday', 'NOUN'),\n",
       " ('an', 'DET'),\n",
       " ('investigation', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " (\"Atlanta's\", 'NOUN'),\n",
       " ('recent', 'ADJ'),\n",
       " ('primary', 'NOUN'),\n",
       " ('election', 'NOUN'),\n",
       " ('produced', 'VERB'),\n",
       " ('``', '.'),\n",
       " ('no', 'DET'),\n",
       " ('evidence', 'NOUN'),\n",
       " (\"''\", '.'),\n",
       " ('that', 'ADP'),\n",
       " ('any', 'DET'),\n",
       " ('irregularities', None),\n",
       " ('took', 'VERB'),\n",
       " ('place', 'NOUN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import UnigramTagger\n",
    "\n",
    "# Unigram-Tagger beim Lernen\n",
    "ut = UnigramTagger(brown_train)\n",
    "\n",
    "ut.tag(brown_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wieder können wir mit `evaluate()` die Accuracy des Taggers anhand von Goldtestdaten ermitteln:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8888888888888888"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ut.evaluate(brown_testgold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Ergebnis ist mit 88,9% deutlich besser als beim Default-Tagger und beim Regexp-Tagger. \n",
    "\n",
    "Kann man sich damit zufrieden geben? Leider nein! Da die Accuracy bezogen auf Worte berechnet wird, bedeutet das, dass durchschnittlich etwa jedes 10. Wort falsch getaggt wird. In jedem durschnittlich großen Satz von 20 Worten gibt es also durchschnittlich zwei Fehler. Das ist für eine Methode, die immer noch relativ am Anfang der Verarbeitungspipeline steht, zu viel. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Aufgaben II: Unbekannte Worte</span>\n",
    "\n",
    "Wir müssen also weiterhin nach Verbesserungsmöglichkeiten Ausschau halten -- und in der Ausgabe von `ut` fällt sofort eine Verbesserungsmöglichkeit auf: Manche Wortformen haben das POS-Tag `none` erhalten, weil sie in den Trainingsdaten nicht gesehen wurden. Das sind die sogenannten **unbekannten Worte** (\"unknown words\").\n",
    "\n",
    "<span style=\"color:red\">A2:</span> Überlegen Sie sich eine Strategie, mit der der Unigram-Tagger auch bei unbekannten Worten ein sinnvolles POS-Tag zuweist, implementieren Sie diese Strategie als Tagger `utplus` und berechnen Sie die Accuracy von `utplus`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9519400352733686"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lösung A2\n",
    "# according to the documentation, UnigramTaggers can be extended by using a \"backoff\" \n",
    "# parameter to use if the UnigrammTagger does not find the corresponding tag\n",
    "# so so can use a RegexpTagger if the unigramTagger fails tagging as backoff.\n",
    "\n",
    "regexp_tagger = nltk.RegexpTagger([\n",
    "    # added expressions\n",
    "    (r'.*ies$', 'NOUN'),                   # plural nouns singularities\n",
    "    (r'.*ize$', 'VERB'),                   # nouns formed from verbs verbal noun\n",
    "    (r'(January|February|March|April|May|June|July|August|September|October|November|December)$', 'NOUN'),\n",
    "    #------------------------------------------------\n",
    "    (r'(The|the|A|a|An|an)$', 'DET'),      # articles\n",
    "    (r'.*able$', 'ADJ'),                   # adjectives\n",
    "    (r'.*ness$', 'NOUN'),                  # nouns formed from adjectives\n",
    "    (r'.*ly$', 'ADV'),                     # adverbs\n",
    "    (r'.*ing$', 'VERB'),                   # gerunds\n",
    "    (r'.*ed$', 'VERB'),                    # simple past\n",
    "    (r'.*es$', 'VERB'),                    # 3rd singular present\n",
    "    (r'.*ould$', 'VERB'),                  # modals\n",
    "    (r'.*\\'s$', 'NOUN'),                   # possessive nouns\n",
    "    (r'.*s$', 'NOUN'),                     # plural nouns\n",
    "    (r'^-?[0-9]+(\\.[0-9]+)?$', 'NUM'),     # cardinal numbers\n",
    "    (r'(\\.|\\,|\\(|\\)|\\;|\\`\\`|\\'\\')$', '.'), # punctuation\n",
    "    (r'.*', 'NOUN'),                       # nouns (default)\n",
    "    ])\n",
    "\n",
    "utplus = UnigramTagger(brown_train, backoff=regexp_tagger)\n",
    "utplus.evaluate(brown_testgold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DET'),\n",
       " ('Fulton', 'NOUN'),\n",
       " ('County', 'NOUN'),\n",
       " ('Grand', 'ADJ'),\n",
       " ('Jury', 'NOUN'),\n",
       " ('said', 'VERB'),\n",
       " ('Friday', 'NOUN'),\n",
       " ('an', 'DET'),\n",
       " ('investigation', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " (\"Atlanta's\", 'NOUN'),\n",
       " ('recent', 'ADJ'),\n",
       " ('primary', 'NOUN'),\n",
       " ('election', 'NOUN'),\n",
       " ('produced', 'VERB'),\n",
       " ('``', '.'),\n",
       " ('no', 'DET'),\n",
       " ('evidence', 'NOUN'),\n",
       " (\"''\", '.'),\n",
       " ('that', 'ADP'),\n",
       " ('any', 'DET'),\n",
       " ('irregularities', 'NOUN'),\n",
       " ('took', 'VERB'),\n",
       " ('place', 'NOUN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utplus.tag(brown_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-Gram-Tagger\n",
    "\n",
    "Eine grundlegende Einschränkung des Lookup-Taggers (bzw. des Unigram-Taggers) ist, dass der Kontext des Worttokens nicht berücksichtigt wird. Der Kontext ist aber oft wichtig, da vielen Wortformen mehr als ein POS-Tag zugewiesen werden kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 'DET'),\n",
       " ('fly', 'NOUN'),\n",
       " ('flies', 'VERB'),\n",
       " ('to', 'PRT'),\n",
       " ('flies', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('order', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('fly', 'NOUN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ut.tag(nltk.word_tokenize(\"A fly flies to flies in order to fly.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Ansatz des N-Gram-Taggers ist daher, den unmittelbaren, vorangehenden Kontext bei der Klassifizierung einzubeziehen. \"N\" steht für die festgelegte Größe des Kontexts: Ein **2-Gram-Tagger** (oder Bigram-Tagger) betrachtet z.B. das zu klassifizierende Wort und das POS-Tag des davorstehenden Worts. Der N-Gram-Tagger ist also eine Generalisierung des Unigram-Taggers. Schematisch kann das folgendermapßen dargestellt werden: \n",
    "\n",
    "![](https://www.nltk.org/images/tag-context.png)\n",
    "\n",
    "In der Umsetzung bedeutet das, dass auch 2- oder 3-Gramme, d.h. Teilketten der Länge 2 bzw. 3, erstellt und statistisch gewichtet werden. N-Grams können mit Hilfe des NLTK-Moduls `ngrams` erstellt und veranschaulicht werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['NOUN'], ('personally', 'ADV')),\n",
       " (['ADV'], ('led', 'VERB')),\n",
       " (['VERB'], ('the', 'DET')),\n",
       " (['DET'], ('fight', 'NOUN')),\n",
       " (['NOUN'], ('for', 'ADP')),\n",
       " (['ADP'], ('the', 'DET')),\n",
       " (['DET'], ('measure', 'NOUN')),\n",
       " (['NOUN'], (',', '.')),\n",
       " (['.'], ('which', 'DET')),\n",
       " (['DET'], ('he', 'PRON')),\n",
       " (['PRON'], ('had', 'VERB')),\n",
       " (['VERB'], ('watered', 'VERB')),\n",
       " (['VERB'], ('down', 'PRT')),\n",
       " (['PRT'], ('considerably', 'ADV')),\n",
       " (['ADV'], ('since', 'ADP')),\n",
       " (['ADP'], ('its', 'DET')),\n",
       " (['DET'], ('rejection', 'NOUN')),\n",
       " (['NOUN'], ('by', 'ADP')),\n",
       " (['ADP'], ('two', 'NUM')),\n",
       " (['NUM'], ('previous', 'ADJ')),\n",
       " (['ADJ'], ('Legislatures', 'NOUN')),\n",
       " (['NOUN'], (',', '.')),\n",
       " (['.'], ('in', 'ADP')),\n",
       " (['ADP'], ('a', 'DET')),\n",
       " (['DET'], ('public', 'ADJ')),\n",
       " (['ADJ'], ('hearing', 'NOUN')),\n",
       " (['NOUN'], ('before', 'ADP')),\n",
       " (['ADP'], ('the', 'DET')),\n",
       " (['DET'], ('House', 'NOUN')),\n",
       " (['NOUN'], ('Committee', 'NOUN')),\n",
       " (['NOUN'], ('on', 'ADP')),\n",
       " (['ADP'], ('Revenue', 'NOUN')),\n",
       " (['NOUN'], ('and', 'CONJ')),\n",
       " (['CONJ'], ('Taxation', 'NOUN')),\n",
       " (['NOUN'], ('.', '.'))]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import ngrams\n",
    "n = 2 \n",
    "input = brown_train[0]\n",
    "[([tag for word,tag in ngram[:n-1]],ngram[n-1]) for ngram in ngrams(input, n)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glücklicherweise gibt es in NLTK bereits eine passende Klasse `NgramTagger`, mit der wir N-Gram-Tagger mit beliebigem N erzeugen können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import NgramTagger\n",
    "\n",
    "bigt = NgramTagger(2, brown_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn wir nun den Satz von oben taggen wollen, werden wir allerdings feststellen, dass ab dem zweiten *flies* alle Worte das POS-Tag `None` erhalten.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 'DET'),\n",
       " ('fly', 'NOUN'),\n",
       " ('flies', 'VERB'),\n",
       " ('to', 'PRT'),\n",
       " ('flies', None),\n",
       " ('in', None),\n",
       " ('order', None),\n",
       " ('to', None),\n",
       " ('fly', None),\n",
       " ('.', None)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigt.tag(nltk.word_tokenize(\"A fly flies to flies in order to fly.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das liegt daran, dass in den Trainingsdaten *flies* nicht hinter `PRT` auftritt und deswegen als `None` klassifiziert wird. Da aber `None` für den Bigram-Tagger auch ein unbekannter Kontext ist, setzt sich der Fehler bis zum Ende fort.\n",
    "\n",
    "Um dem entgegenzuwirken, muss man eine Rückfall-Strategie (\"backoff\") angeben. Das ist mit der Option `backoff` möglich und hier setzen wir einfach den Unigram-Tagger von oben ein:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 'DET'),\n",
       " ('fly', 'NOUN'),\n",
       " ('flies', 'VERB'),\n",
       " ('to', 'PRT'),\n",
       " ('flies', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('order', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('fly', 'VERB'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import NgramTagger\n",
    "\n",
    "bigt = NgramTagger(2, brown_train,backoff=ut)\n",
    "bigt.tag(nltk.word_tokenize(\"A fly flies to flies in order to fly.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der Evaluation sehen wir, dass der Bigram-Tagger mit dem Unigram-Tagger als Backoff zu leicht verbesserter Accuracy führt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8963844797178131"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigt.evaluate(brown_testgold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun bedeutet \"mehr\" nicht notwendigerweise \"besser\". Wenn wir nämlich mehr Kontext berücksichtigen und stattdessen einen **Trigram-Tagger** implementieren, dann erhalten wir im Vergleich zum Bigram-Tagger eine leicht verringerte Accuracy: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.892416225749559"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigt = NgramTagger(3, brown_train, backoff=ut)\n",
    "trigt.evaluate(brown_testgold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Grund dafür ist die unentrinnbare Datenknappheit: Der Trigram-Tagger wird häufiger als der Bigram-Tagger in die Situation kommen, dass ein Trigram in den Lerndaten nicht gesehen wurde und daher das Ergebnis des Backoff-Taggers übernommen werden muss. Die Accuracy der N-Gram-Tagger nähert sich also mit wachsendem N der Accuracy des Backoffs an.\n",
    "\n",
    "### <span style=\"color:red\">Aufgaben III</span>\n",
    "\n",
    "Wir sind nun bereit für den letzten Schritt.\n",
    "\n",
    "<span style=\"color:red\">A2:</span> Implementieren Sie einen POS-Tagger `ngt`, der die N-Gram-Tagger per `backoff` so kombiniert, dass die Accuracy möglichst hoch ausfällt! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigt = NgramTagger(2, brown_train,backoff=utplus)\n",
    "trigt = NgramTagger(3, brown_train, backoff=bigt)\n",
    "quagt = NgramTagger(4, brown_train, backoff=trigt)\n",
    "fivgt = NgramTagger(5, brown_train, backoff=quagt)\n",
    "sixgt = NgramTagger(6, brown_train, backoff=fivgt)\n",
    "sevgt = NgramTagger(7, brown_train, backoff=sixgt)\n",
    "eiggt = NgramTagger(8, brown_train, backoff=sevgt)\n",
    "ningt = NgramTagger(9, brown_train, backoff=eiggt)\n",
    "tengt = NgramTagger(10, brown_train, backoff=ningt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lösung A3\n",
    "# ngt = NgramTagger(1, brown_train) # Bitte überschreiben/ändern!\n",
    "ngt = NgramTagger(2, brown_train,backoff=utplus)\n",
    "# seems to be the strongest for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9585537918871252\n"
     ]
    }
   ],
   "source": [
    "# probably the strongs tagger\n",
    "# 2-Gram-Tagger with utplus as backoff (utplus = UnigramTagger)\n",
    "print(ngt.evaluate(brown_testgold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9576719576719577"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigt.evaluate(brown_testgold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.955026455026455"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quagt.evaluate(brown_testgold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9514991181657848"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fivgt.evaluate(brown_testgold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9484126984126984"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sixgt.evaluate(brown_testgold) # seems like with more than 6 the algorithm converges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9484126984126984"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sevgt.evaluate(brown_testgold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9484126984126984"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eiggt.evaluate(brown_testgold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9484126984126984"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ningt.evaluate(brown_testgold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9484126984126984"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tengt.evaluate(brown_testgold) # 11-gram-Tagger with nested 10-Gram-Tagger ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
