{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Abgegeben von (Name, Vorname):</span> \n",
    "Goxhufi, Driton\n",
    "\n",
    "# WordNet: Ein semantisches Lexikon \n",
    "\n",
    "Für dieses Notebook gibt es eine begeleitendes Skript auf Ilias: `skript-wordnet.pdf`\n",
    "\n",
    "## Über WordNet\n",
    "\n",
    "[WordNet](https://wordnet.princeton.edu) ist eine manuell erstellte Datenbank, in der (Ketten von) Wortformen (genauer gesagt Lemmata) durch semantische Relationen miteinander verbunden sind. WordNet bildet also ein semantisches Netz.\n",
    "\n",
    "Die Knoten bilden sogenannte **Synsets**, Mengen von (Ketten von) Lemmata, die in bestimmten Kontexten **synonym** sind.\n",
    "- Beispiel: {*bank*, *financial institute*}\n",
    "\n",
    "Semantische Relationen zwischen Synsets:\n",
    "- Hyponymie (`is-a`): *fly* $\\rightarrow$ *travel*\n",
    "- Troponymie (`is-a`): *walk* $\\rightarrow$ *stroll* \n",
    "- Meronymie (`part-of`): *leg* $\\rightarrow$ *table*\n",
    "- Folgebeziehung: *snore* $\\rightarrow$ *sleep* \n",
    "- Antonymie: *increase* $\\leftrightarrow$ *decrease*\n",
    "- derivationelle Beziehung: *destroy* $\\leftrightarrow$ *destruction*\n",
    "\n",
    "Umfang Version 3.1 von 2012 (Quelle [Wikipedia](https://en.wikipedia.org/wiki/WordNet)):\n",
    "- 155 327 Lemmata\n",
    "- 175 979 Synsets (~Bedeutungen)\n",
    "- 207 016 Lemma-Synset-Paare\n",
    "- durchschn. Lemma-Ambiguität: 1,34\n",
    "- durchschn. Synset-Umfang: 1,176 \n",
    "\n",
    "WordNet enthält eigentlich 4 fast getrennte Teilnetze entsprechend der Wortart der Lemmata (Quelle [Jurafsky & Martin](https://web.stanford.edu/~jurafsky/slp3/19.pdf)):\n",
    "- Nomen: 117 798 (1,23 Bedeutungen/Lemma)\n",
    "- Verben: 11 529 (2,16 Bedeutungen/Lemma)\n",
    "- Adjektive: 22 479\n",
    "- Adverbien: 4 481\n",
    " \n",
    "## Installation in NLTK\n",
    "\n",
    "WordNet steht für NLTK als Download zur Verfügung:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Danach kann WordNet als Korpus importiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einfache Abfragen\n",
    "\n",
    "Die Beschreibung des NLTK-Moduls `wordnet` findet sich hier: https://www.nltk.org/api/nltk.corpus.reader.html#module-nltk.corpus.reader.wordnet\n",
    "\n",
    "Die abrufbaren Objekte sind \n",
    "- Synsets via `synsets()` und `synset()`\n",
    "- Lemmata via `lemmas()` und `lemma()`\n",
    "\n",
    "### Synsets\n",
    "\n",
    "Eine **Liste von Synsets** abhängig von den darin enthaltenen Lemmata oder POS-Tags kann über die Methode `synsets()` abgerufen werden.\n",
    "\n",
    "Argumente von `synsets(name, pos=None, lang='eng', check_exceptions=True)`\n",
    "- `name`: ein (Teil eines) Lemma-Bezeichners\n",
    "- `pos=`: ein POS-Tag, z.B. `wn.VERB`, `wn.NOUN`, `wn.ADV`, `wn.ADJ`\n",
    "- `lang=`: eine Sprachkürzel, z.B. `eng`, `fra`, `jpn`, ... (siehe `wn.langs()`)\n",
    "- `check_exceptions=True`: weitere morphologische Suche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('bank.n.01'), Synset('depository_financial_institution.n.01'), Synset('bank.n.03'), Synset('bank.n.04'), Synset('bank.n.05'), Synset('bank.n.06'), Synset('bank.n.07'), Synset('savings_bank.n.02'), Synset('bank.n.09'), Synset('bank.n.10'), Synset('bank.v.01'), Synset('bank.v.02'), Synset('bank.v.03'), Synset('bank.v.04'), Synset('bank.v.05'), Synset('deposit.v.02'), Synset('bank.v.07'), Synset('trust.v.01')]\n"
     ]
    }
   ],
   "source": [
    "print(wn.synsets('bank'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativ kann mit `synset(synsetName)` ein einzelnes Synset aufgrund eines vollständigen Bezeichners abgerufen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('bank.n.01')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('bank.n.01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es gibt eine Reihe von Methoden, mit deren Hilfe auf Attribute eines Synset-Objekts zugegriffen werden können. \n",
    "- `name()`: der Bezeichner des Synsets als String\n",
    "- `pos()`: das POS-Tag des Synsets\n",
    "- `lemmas()`: Liste der Lemmata, die zu einem Synset gehören (und deren Wortformen in bestimmten Kontexten synonym sind).\n",
    "- `definition()`: Definition der Bedeutung des Synsets \n",
    "- `examples()`: Liste von Beispielverwendungen des Synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:       bank.n.01\n",
      "POS:        n\n",
      "Lemmata:    [Lemma('bank.n.01.bank')]\n",
      "Definition: sloping land (especially the slope beside a body of water)\n",
      "Beispiele:  ['they pulled the canoe up on the bank', 'he sat on the bank of the river and watched the currents']\n"
     ]
    }
   ],
   "source": [
    "print(\"Name:       \" + str(wn.synset('bank.n.01').name()))\n",
    "print(\"POS:        \" + str(wn.synset('bank.n.01').pos()))\n",
    "print(\"Lemmata:    \" + str(wn.synset('bank.n.01').lemmas()))\n",
    "print(\"Definition: \" + str(wn.synset('bank.n.01').definition()))\n",
    "print(\"Beispiele:  \" + str(wn.synset('bank.n.01').examples()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Man beachte, dass man bei `lemmas()` die oben schon erwähnten Sprach-Codes verwenden kann: `eng`, `fra`, `jpn`, ... (siehe `wn.langs()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('bank.n.01.banque'), Lemma('bank.n.01.rive')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bevor das funktioniert hat, musste man die packages von nltk:\n",
    "# nltk.download() \n",
    "# davon zusätzlich noch runterladen.\n",
    "wn.synset('bank.n.01').lemmas('fra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('bank.n.01.土手'),\n",
       " Lemma('bank.n.01.岸'),\n",
       " Lemma('bank.n.01.岸べ'),\n",
       " Lemma('bank.n.01.岸辺'),\n",
       " Lemma('bank.n.01.斜面')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('bank.n.01').lemmas(lang='jpn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Synsets sind also sprachunabhängig!\n",
    "\n",
    "### Lemmata [eigentlich Lexeme]\n",
    "\n",
    "Spiegelbildlich zu `synsets()` und `synset()` gibt es `lemmas(name, pos=None, lang='eng')` und `lemma(name, lang='eng')`.\n",
    "\n",
    "**ACHTUNG:** NLTK verwendet den Lemma-Begriff so: \"The lexical entry for a single morphological form of a sense-disambiguated word.\" Dies entspricht eigentlich eher dem, was wir im Skript `skript-lexicon.pdf` ein **Lexem** genannt haben. Lexeme sind Lemmata mit einer festgelegten Bedeutung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lemma('bank.n.01.bank'), Lemma('depository_financial_institution.n.01.bank'), Lemma('bank.n.03.bank'), Lemma('bank.n.04.bank'), Lemma('bank.n.05.bank'), Lemma('bank.n.06.bank'), Lemma('bank.n.07.bank'), Lemma('savings_bank.n.02.bank'), Lemma('bank.n.09.bank'), Lemma('bank.n.10.bank'), Lemma('bank.v.01.bank'), Lemma('bank.v.02.bank'), Lemma('bank.v.03.bank'), Lemma('bank.v.04.bank'), Lemma('bank.v.05.bank'), Lemma('deposit.v.02.bank'), Lemma('bank.v.07.bank'), Lemma('trust.v.01.bank')]\n",
      "Lemma('bank.n.01.bank')\n"
     ]
    }
   ],
   "source": [
    "print(wn.lemmas('bank'))\n",
    "print(wn.lemma('bank.n.01.bank'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie bei `synset()` gibt eine Reihe von Methoden, mit deren Hilfe auf Attribute des Lemma-Objekts zugegriffen werden können. \n",
    "- `name()`: der Bezeichner des Synsets als String\n",
    "- `synsets()`: Liste der Synsets, in denen das Lemma erscheint\n",
    "- `count()`: Anzahl \"in WordNet\". Tatsächlich ist dies die Anzahl der Lemma/Lexem-Verwendungen in **SemCor** (siehe unten). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:              bank\n",
      "Synsets:           Synset('bank.n.01')\n",
      "Anzahl in SemCor:  25\n",
      "Anzahl in SemCor:  2\n"
     ]
    }
   ],
   "source": [
    "print(\"Name:              \" + str(wn.lemma('bank.n.01.bank').name()))\n",
    "print(\"Synsets:           \" + str(wn.lemma('bank.n.01.bank').synset()))\n",
    "print(\"Anzahl in SemCor:  \" + str(wn.lemma('bank.n.01.bank').count()))\n",
    "print(\"Anzahl in SemCor:  \" + str(wn.lemma('bank.v.01.bank').count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Anzahl in SemCor (via `count()`) ist beispielsweise wichtig für Verfahren, die Worten automatisch eine Bedeutung zuweisen. \n",
    "\n",
    "### <span style=\"color:red\">Aufgaben I</span>\n",
    "\n",
    "<span style=\"color:red\">A1:</span> Schreiben Sie eine Funktion `mfs_of(lemma,tag)`, die für eine Lemmaform und ein POS-Tag aus $\\{n,v,a,r,s\\}$ die in SemCor am häufigsten zugewiesenen Synsets ausgibt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synsets tests:  Synset('bank.n.01')\n"
     ]
    }
   ],
   "source": [
    "print(\"synsets tests:  \" + str(wn.lemma('bank.n.01.bank').synset()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('bank.n.01'),\n",
       " Synset('depository_financial_institution.n.01'),\n",
       " Synset('bank.n.03'),\n",
       " Synset('bank.n.04'),\n",
       " Synset('bank.n.05'),\n",
       " Synset('bank.n.06'),\n",
       " Synset('bank.n.07'),\n",
       " Synset('savings_bank.n.02'),\n",
       " Synset('bank.n.09'),\n",
       " Synset('bank.n.10')]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('bank', pos='n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('bank.n.01'), Synset('depository_financial_institution.n.01'), Synset('bank.n.03'), Synset('bank.n.04'), Synset('bank.n.05'), Synset('bank.n.06'), Synset('bank.n.07'), Synset('savings_bank.n.02'), Synset('bank.n.09'), Synset('bank.n.10')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synset = wn.synsets('bank', pos='n')\n",
    "print(synset)\n",
    "sum(lemma.count() for lemma in synset[0].lemmas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Synset('bank.n.01'): 25, Synset('depository_financial_institution.n.01'): 20, Synset('bank.n.03'): 2, Synset('bank.n.04'): 1, Synset('bank.n.05'): 0, Synset('bank.n.06'): 0, Synset('bank.n.07'): 0, Synset('savings_bank.n.02'): 0, Synset('bank.n.09'): 0, Synset('bank.n.10'): 0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Synset('bank.n.01')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lösung A1\n",
    "\n",
    "def mfs_of(lemma,tag) :\n",
    "    mfs = {}\n",
    "    for i in wn.synsets(lemma, pos=tag):\n",
    "        mfs[i] = sum(j.count() for j in i.lemmas())    \n",
    "    print(mfs)\n",
    "    return max(mfs, key=mfs.get)\n",
    "    \n",
    "mfs_of('bank','n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Synset('car.n.01'): 89, Synset('car.n.02'): 2, Synset('car.n.03'): 0, Synset('car.n.04'): 0, Synset('cable_car.n.01'): 0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Synset('car.n.01')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfs_of('car','n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glückwunsch! Sie haben soeben eine wichtige Baseline bei der Evaluierung von Disambiguierungsverfahren erstellt. \n",
    "\n",
    "Diese Baseline heißt üblicherweise **MFS-Baseline**, weil einfach nur der \"most frequent sense\" ausgewählt wird.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantische Relationen \n",
    "\n",
    "Sowohl für Synsets als auch Lemmata gibt es Funktionen für die Abfrage der semantischen Relationen zwischen diesen Objekten.\n",
    "\n",
    "#### Hypernymie, Hyponymie, Meronomie, Holonymie (Lemmata & Synsets)\n",
    "\n",
    "- `hypernyms()`: Liste der Hypernyme (*table* $\\rightarrow$ *array*)\n",
    "- `hyponyms()`: Liste der Hyponyme (*table* $\\rightarrow$ *calendar*)\n",
    "- `member_holonyms()`, `substance_holonyms()`, `part_holonyms()`: Holonymiebeziehungen\n",
    "- `member_meronyms()`, `substance_meronyms()`, `part_meronyms()`: Meronymiebeziehungen\n",
    "- `entailments()`: Liste der Implikationen (*snore* $\\rightarrow$ *sleep*)\n",
    "- `causes()`: Liste der Ursachen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('war.n.01')\n",
      "Hypernyme:          [Synset('military_action.n.01')]\n",
      "Hyponyme:           [Synset('biological_warfare.n.01'), Synset('chemical_warfare.n.01'), Synset('civil_war.n.01'), Synset('hot_war.n.01'), Synset('information_warfare.n.01'), Synset('jihad.n.01'), Synset('limited_war.n.01'), Synset('psychological_warfare.n.01'), Synset('world_war.n.01')]\n",
      "Mitglied-Holonyme:  []\n",
      "Substanz-Holonyme:  []\n",
      "Teil-Holonyme:      []\n",
      "Implikationen:      []\n",
      "Ursachen:           []\n"
     ]
    }
   ],
   "source": [
    "syns = wn.synset('war.n.01')\n",
    "\n",
    "print(syns)\n",
    "print(\"Hypernyme:          {}\".format(syns.hypernyms()))\n",
    "print(\"Hyponyme:           {}\".format(syns.hyponyms()))\n",
    "print(\"Mitglied-Holonyme:  {}\".format(syns.member_holonyms()))\n",
    "print(\"Substanz-Holonyme:  {}\".format(syns.substance_holonyms()))\n",
    "print(\"Teil-Holonyme:      {}\".format(syns.part_holonyms()))\n",
    "print(\"Implikationen:      {}\".format(syns.entailments()))\n",
    "print(\"Ursachen:           {}\".format(syns.causes()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Antonymie, Related Forms (nur Lemmata)\n",
    "\n",
    "Für Lemmata gibt es außerdem noch zwei spezielle Relationen:\n",
    "\n",
    "- `antonyms()`: Liste der Antonyme (*dead* $\\rightarrow$ *living*)\n",
    "- `derivationally_related_forms()`: Liste der Lemmata mit derivationellem Bezug (*decision* $\\rightarrow$ *decide*)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma('decision.n.01.decision')\n",
      "Antonyme:                  []\n",
      "mit derivationallem Bezug: [Lemma('decide.v.01.decide')]\n"
     ]
    }
   ],
   "source": [
    "lem = wn.lemmas('decision')[0]\n",
    "\n",
    "print(lem)\n",
    "print(\"Antonyme:                  {}\".format(lem.antonyms()))\n",
    "print(\"mit derivationallem Bezug: {}\".format(lem.derivationally_related_forms()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indirekte Beziehungen (nur Synsets)\n",
    "\n",
    "Die Position im semantischen Graphen kann mit folgenden Funktionen ermittelt werden:\n",
    "\n",
    "- `max_depth()`: maximaler Hyponymie-Pfad\n",
    "- `min_depth()`: min Hyponymie-Pfad\n",
    "- `root_hypernyms(synset)`: Lister der Wurzel-Synsets\n",
    "- `tree(rel)`: Ausgabe der `rel`-Pfade zu den Wurzel-Synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('war.n.01')\n",
      "minimale Tiefe: 6\n",
      "maximale Tiefe: 7\n",
      "Wurzel-Synsets: [Synset('entity.n.01')]\n",
      "Relationspfade zum Wurzel-Synset:\n",
      "[Synset('war.n.01'),\n",
      " [Synset('military_action.n.01'),\n",
      "  [Synset('group_action.n.01'),\n",
      "   [Synset('act.n.02'),\n",
      "    [Synset('event.n.01'),\n",
      "     [Synset('psychological_feature.n.01'),\n",
      "      [Synset('abstraction.n.06'), [Synset('entity.n.01')]]]]],\n",
      "   [Synset('event.n.01'),\n",
      "    [Synset('psychological_feature.n.01'),\n",
      "     [Synset('abstraction.n.06'), [Synset('entity.n.01')]]]]]]]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "syns = wn.synset('war.n.01')\n",
    "hyp = lambda s:s.hypernyms()\n",
    "\n",
    "print(syns)\n",
    "print(\"minimale Tiefe: {}\".format(syns.min_depth()))\n",
    "print(\"maximale Tiefe: {}\".format(syns.max_depth()))\n",
    "print(\"Wurzel-Synsets: {}\".format(syns.root_hypernyms()))\n",
    "print(\"Relationspfade zum Wurzel-Synset:\")\n",
    "pprint(syns.tree(hyp))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gemeinsame Hypernyme (nur Synsets)\n",
    "\n",
    "NLTK stellt auch Funktionen zur Verfügung, um gemeinsem Hypernyme auszugeben:\n",
    "\n",
    "- `common_hypernyms(synset)`: Liste der gemeinsamen der Hypernyme\n",
    "- `lowest_common_hypernyms(synset)`: Liste der nächhsten gemeinsamen Hyponyme\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('bank.n.01'), Synset('sea.n.01')]\n",
      "Gemeinsame Hypernyme:              [Synset('physical_entity.n.01'), Synset('entity.n.01')]\n",
      "Die nächsten gemeinsame Hypernyme: [Synset('physical_entity.n.01')]\n"
     ]
    }
   ],
   "source": [
    "syns1 = wn.synset('bank.n.01')\n",
    "syns2 = wn.synset('sea.n.01')\n",
    "\n",
    "print([syns1, syns2])\n",
    "print(\"Gemeinsame Hypernyme:              {}\".format(syns1.common_hypernyms(syns2)))\n",
    "print(\"Die nächsten gemeinsame Hypernyme: {}\".format(syns1.lowest_common_hypernyms(syns2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Aufgaben II</span>\n",
    "\n",
    "<span style=\"color:red\">A2:</span> Schreiben Sie die Funktionen `common_hyponyms(synset1,synset2)` und `highest_common_hyponyms(synset1,synset2)`, die für zwei Synsets alle gemeinsamen Hyponyme bzw. die \"höchsten\" gemeinsamen Hyponyme ausgibt!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('riverbank.n.01'), Synset('waterside.n.01')]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bankhypo = wn.synset('bank.n.01').hyponyms()\n",
    "bankhypo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank = bankhypo[0].hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('slope.n.01')]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank[0].hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('physical_entity.n.01')]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('bank.n.01').lowest_common_hypernyms(wn.synset('physical_entity.n.01'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('causal_agent.n.01'),\n",
       " Synset('matter.n.03'),\n",
       " Synset('object.n.01'),\n",
       " Synset('process.n.06'),\n",
       " Synset('substance.n.04'),\n",
       " Synset('thing.n.12')]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('physical_entity.n.01').hyponyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('agnate.n.01'), Synset('ancestor.n.01'), Synset('blood_relation.n.01'), Synset('cousin.n.01'), Synset('descendant.n.01'), Synset('enate.n.01'), Synset('in-law.n.01'), Synset('kin.n.01'), Synset('kinsman.n.01'), Synset('kinswoman.n.01'), Synset('kissing_cousin.n.01'), Synset('next_of_kin.n.01'), Synset('offspring.n.01'), Synset('second_cousin.n.01'), Synset('sibling.n.01'), Synset('spouse.n.01'), Synset('ancestress.n.01'), Synset('forebear.n.01'), Synset('forefather.n.01'), Synset('foremother.n.01'), Synset('progenitor.n.01'), Synset('child.n.04'), Synset('scion.n.01'), Synset('brother-in-law.n.01'), Synset('daughter-in-law.n.01'), Synset('father-in-law.n.01'), Synset('mother-in-law.n.01'), Synset('sister-in-law.n.01'), Synset('son-in-law.n.01'), Synset('affine.n.01'), Synset('male_sibling.n.01'), Synset('nephew.n.01'), Synset('uncle.n.01'), Synset('aunt.n.01'), Synset('female_sibling.n.01'), Synset('niece.n.01'), Synset('baby.n.02'), Synset('bastard.n.02'), Synset('child.n.02'), Synset('firstborn.n.01'), Synset('grandchild.n.01'), Synset('successor.n.03'), Synset('half_blood.n.01'), Synset('quadruplet.n.02'), Synset('quintuplet.n.02'), Synset('triplet.n.02'), Synset('twin.n.01'), Synset('bigamist.n.01'), Synset('consort.n.01'), Synset('helpmate.n.01'), Synset('husband.n.01'), Synset('monogamist.n.01'), Synset('newlywed.n.01'), Synset('polygamist.n.01'), Synset('wife.n.01'), Synset('grandparent.n.01'), Synset('great_grandparent.n.01'), Synset('patriarch.n.03'), Synset('genitor.n.01'), Synset('brother.n.01'), Synset('great-nephew.n.01'), Synset('great-uncle.n.01'), Synset('great-aunt.n.01'), Synset('maiden_aunt.n.01'), Synset('sister.n.01'), Synset('great-niece.n.01'), Synset('army_brat.n.01'), Synset('baby.n.01'), Synset('female_offspring.n.01'), Synset('male_offspring.n.01'), Synset('stepchild.n.01'), Synset('granddaughter.n.01'), Synset('grandson.n.01'), Synset('great_grandchild.n.01'), Synset('fraternal_twin.n.01'), Synset('identical_twin.n.01'), Synset('prince_consort.n.01'), Synset('benedick.n.01'), Synset('cuckold.n.01'), Synset('family_man.n.01'), Synset('house_husband.n.01'), Synset('uxoricide.n.01'), Synset('bride.n.01'), Synset('groom.n.03'), Synset('polyandrist.n.01'), Synset('polygynist.n.01'), Synset('battle-ax.n.02'), Synset('crown_princess.n.01'), Synset('first_lady.n.02'), Synset('golf_widow.n.01'), Synset('honest_woman.n.01'), Synset('housewife.n.01'), Synset('marchioness.n.01'), Synset('matron.n.01'), Synset('mayoress.n.01'), Synset('missus.n.01'), Synset('old_lady.n.01'), Synset('sheika.n.01'), Synset('signora.n.01'), Synset('trophy_wife.n.01'), Synset('uxor.n.01'), Synset('vicereine.n.01'), Synset('viscountess.n.01'), Synset('grandfather.n.01'), Synset('grandma.n.01'), Synset('great_grandfather.n.01'), Synset('great_grandmother.n.01'), Synset('antediluvian.n.01'), Synset('jacob.n.02'), Synset('simeon.n.01'), Synset('parent.n.01'), Synset('big_brother.n.02'), Synset('little_brother.n.01'), Synset('stepbrother.n.01'), Synset('big_sister.n.01'), Synset('half_sister.n.01'), Synset('little_sister.n.01'), Synset('blue_baby.n.01'), Synset('cherub.n.01'), Synset('foundling.n.01'), Synset('godchild.n.01'), Synset('neonate.n.01'), Synset('nursling.n.01'), Synset('papoose.n.01'), Synset('test-tube_baby.n.01'), Synset('war_baby.n.01'), Synset('daughter.n.01'), Synset('son.n.01'), Synset('stepdaughter.n.01'), Synset('stepson.n.01'), Synset('great_granddaughter.n.01'), Synset('great_grandson.n.01'), Synset('siamese_twin.n.01'), Synset('wittol.n.01'), Synset('war_bride.n.01'), Synset('nan.n.01'), Synset('adoptive_parent.n.01'), Synset('empty_nester.n.01'), Synset('father.n.01'), Synset('filicide.n.01'), Synset('mother.n.01'), Synset('stepparent.n.01'), Synset('goddaughter.n.01'), Synset('godson.n.01'), Synset('liveborn_infant.n.01'), Synset('low-birth-weight_baby.n.01'), Synset('postmature_infant.n.01'), Synset('premature_baby.n.01'), Synset('small-for-gestational-age_infant.n.01'), Synset('stillborn_infant.n.01'), Synset('term_infant.n.01'), Synset('mother's_daughter.n.01'), Synset('junior.n.04'), Synset('mother's_boy.n.01'), Synset('dad.n.01'), Synset('old_man.n.03'), Synset('pater.n.01'), Synset('ma.n.01'), Synset('mater.n.01'), Synset('primipara.n.01'), Synset('puerpera.n.01'), Synset('quadripara.n.01'), Synset('quintipara.n.01'), Synset('supermom.n.01'), Synset('surrogate_mother.n.01'), Synset('stepfather.n.01'), Synset('stepmother.n.01')]\n"
     ]
    }
   ],
   "source": [
    "physical_entity = wn.synsets('physical_entity', 'n')[0]\n",
    "hypos = lambda s:s.hyponyms()\n",
    "\n",
    "print(list(relative.closure(hypos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "1\n",
      "5\n",
      "1\n",
      "0\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "all_common_hypos = common_hyponyms(wn.synset('bank.n.01'), wn.synset('physical_entity.n.01'))\n",
    "high = 0\n",
    "print(wn.synset('bank.n.01').max_depth())\n",
    "print(wn.synset('physical_entity.n.01').max_depth())\n",
    "print(wn.synset('bank.n.01').min_depth())\n",
    "print(wn.synset('physical_entity.n.01').min_depth())\n",
    "for i in all_common_hypos:\n",
    "    if i.max_depth() > high:\n",
    "        print(high)\n",
    "        high = i.max_depth()\n",
    "        print(i.max_depth())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################\n",
    "##################################### Lösung A2 ######################################\n",
    "######################################################################################\n",
    "def common_hyponyms(synset1, synset2):\n",
    "    common = []\n",
    "    hypos = lambda s:s.hyponyms()\n",
    "\n",
    "    hyponyms1 = list(synset1.closure(hypos))\n",
    "    hyponyms2 = list(synset2.closure(hypos))\n",
    "    for i in hyponyms1:\n",
    "        for j in hyponyms2:\n",
    "            if i == j:\n",
    "                common.append(i)       \n",
    "    return common\n",
    "\n",
    "def highest_common_hyponyms(synset1, synset2):\n",
    "    #print(\"maxdepth of synset1 = \", synset1.max_depth())\n",
    "    #print(\"maxdepth of synset2 = \", synset2.max_depth())\n",
    "    common = common_hyponyms(synset1, synset2)\n",
    "    max_depth = 0\n",
    "    for i in common:\n",
    "        if i.max_depth() > max_depth:\n",
    "            max_depth = i.max_depth()\n",
    "    highest = []\n",
    "    for j in common:\n",
    "        if j.max_depth() == max_depth:\n",
    "            highest.append(j)\n",
    "    return highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('riverbank.n.01'), Synset('waterside.n.01')]\n",
      "[Synset('riverbank.n.01'), Synset('waterside.n.01')]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Tests\n",
    "\n",
    "print(common_hyponyms(wn.synset('bank.n.01'),wn.synset('physical_entity.n.01')))\n",
    "print(highest_common_hyponyms(wn.synset('bank.n.01'),wn.synset('physical_entity.n.01')))\n",
    "print(highest_common_hyponyms(wn.synset('bank.n.01'),wn.synset('sea.n.01')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('riverbank.n.01').max_depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('waterside.n.01').max_depth()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
